{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79b4ef71",
   "metadata": {},
   "source": [
    "# Discrete Disjunctive Kriging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6de5153",
   "metadata": {},
   "source": [
    "<!-- SUMMARY: An example for Discrete Disjunctive Kriging (DDK) -->\n",
    "\n",
    "<!-- CATEGORY: Methodology -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4fb004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gstlearn as gl\n",
    "import gstlearn.plot as gp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811ca457",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18fc5b65",
   "metadata": {},
   "source": [
    "This notebook presents an example for Discrete-Disjunctive Kriging (DDK). The theory is not detailed here, see for example:  \n",
    "Rivoirard, J. (1994). Introduction to disjunctive kriging and non-linear geostatistics. Number\n",
    "551.021 R626i. Clarendon Press"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d10166d",
   "metadata": {},
   "source": [
    "## Simulation of a reference data set\n",
    "We create a reference data set (lognormal distribution) based on a model that we define, using *simtub* (based on Turning Bands)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fd0fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for the simulation\n",
    "m   = 1.\n",
    "sig = 0.5\n",
    "\n",
    "# initialization of the grid\n",
    "grd = gl.DbGrid.create(x0=(0.0,0.0), dx=(0.01,0.01), nx=(100,100))\n",
    "\n",
    "# simulation from a model\n",
    "model = gl.Model.createFromParam(gl.ECov.EXPONENTIAL, range=0.2)\n",
    "gl.simtub(dbin = None, dbout = grd, model = model, nbsimu = 1)\n",
    "grd.setName(\"Simu\", \"Y\")\n",
    "grd[\"Z\"] = m * np.exp(sig * grd[\"Y\"].squeeze() - sig**2 / 2)\n",
    "\n",
    "# Data set (10% of the grid)\n",
    "data = gl.Db.createSamplingDb(grd, 0.1, flagAddSampleRank=0)\n",
    "data.useSel = True\n",
    "\n",
    "# plots\n",
    "fig, (ax1,ax2) = gp.init(1,2, figsize=(15,6))\n",
    "ax1.raster(grd,\"Z\")\n",
    "ax1.decoration(title=\"Initial variable\")\n",
    "ax2.histogram(grd, name='Z',  bins = 25, color=\"orange\")\n",
    "ax2.decoration(xlabel = \"Raw variable\", title=\"Histogram of the initial variable\")\n",
    "\n",
    "fig, ax3 = gp.init(figsize=(6,6))\n",
    "ax3.raster(grd,\"Z\")\n",
    "ax3.symbol(data,nameSize=\"Z\", c='yellow')\n",
    "ax3.decoration(title=\"Random data subsample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6444676f",
   "metadata": {},
   "source": [
    "#### Elementary statistics\n",
    "\n",
    "We define cutoffs values corresponding to quantiles 0\\%, 30\\%, 50\\%, 70\\% and 90\\%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da7d4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "zcut = np.quantile(data['Z'], q = [0.3, 0.5, 0.7, 0.9])\n",
    "\n",
    "print(\"\\n{:^40}\".format(\"Coupures sur la variable Z\"))\n",
    "print(\"{:^10}{:^10}{:^10}{:^10}\".format(0.3, 0.5, 0.7, 0.9))\n",
    "print(\"{:^10.3f}{:^10.3f}{:^10.3f}{:^10.3f}\".format(*zcut),'\\n')\n",
    "\n",
    "mylimits = gl.Limits(zcut, True) #defines limits based on the cutoff values \n",
    "# True for addFromZero, so that we add the interval [0, z_1[\n",
    "mylimits.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f98acb",
   "metadata": {},
   "source": [
    "## Discretization of the variable on cutoff values\n",
    "\n",
    "From the cutoff values defined above, the variable *Z* is discretized on the four intervals delimited by the cutoff values. The indicators of the intervals are $\\mathbb{1}(z_i \\le Z < z_{i+1})$. The fifth indicator ($\\mathbb{1}(Z \\ge z_{5})$) is not computed because it can be deducted from the four other ones as their sum equals to one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e7a048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the indicators (4 new variables)\n",
    "iud_Indic = mylimits.toIndicator(data, name='Z', OptionIndicator=1) \n",
    "# Compute the discretized version of the variable\n",
    "iud_Mean  = mylimits.toIndicator(data, name='Z', OptionIndicator=0) \n",
    "\n",
    "# statistics on the indicators\n",
    "w = gl.dbStatisticsMono(data, [\"Indicator.Z.Class*\"], [gl.EStatOption.MEAN]).getValues()\n",
    "w = list(w) + [1 - np.sum(w)]\n",
    "print(\"Proportions = \", np.round(w,3))\n",
    "Nclass = len(w) # total number of indicators, including the fifth one which is not computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ab73cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)\n",
    "gp.symbol(data, nameColor=\"*Mean\")\n",
    "gp.decoration(title=\"Discretized variable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e73522",
   "metadata": {},
   "source": [
    "## Variography (omnidirectional)\n",
    "\n",
    "#### Variogram of the raw variable *Z*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0171b9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate Z\n",
    "data.clearLocators(gl.ELoc.Z)\n",
    "data.setLocator(\"Z\", gl.ELoc.Z)\n",
    "\n",
    "# Variogram parameters (omnidirectional)\n",
    "varioParam = gl.VarioParam.createOmniDirection(nlag=10, dlag=0.05)\n",
    "# Compute variogram\n",
    "var_Z = gl.Vario.computeFromDb(varioParam, data)\n",
    "\n",
    "# fit model\n",
    "mod_Z = gl.Model()\n",
    "opt=gl.Option_AutoFit()\n",
    "opt.setWmode(2) # weighted proportional to the number of pairs and inverse proportional to the distance\n",
    "mod_Z.fit(var_Z, [gl.ECov.NUGGET, gl.ECov.EXPONENTIAL, gl.ECov.EXPONENTIAL], mauto = opt)\n",
    "\n",
    "# plot\n",
    "gp.varmod(var_Z, mod_Z, flagLegend=True)\n",
    "gp.decoration(title = \"Variogram of the data sample\")\n",
    "\n",
    "mod_Z.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2126bb44",
   "metadata": {},
   "source": [
    "#### Variogram of the discretized variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542d60cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.clearLocators(gl.ELoc.Z)\n",
    "data.setLocator(\"Indicator.Z.Mean\", gl.ELoc.Z)\n",
    "\n",
    "var_Z = gl.Vario.computeFromDb(varioParam, data)\n",
    "\n",
    "mod_Z = gl.Model()\n",
    "mod_Z.fit(var_Z, [gl.ECov.NUGGET, gl.ECov.EXPONENTIAL, gl.ECov.EXPONENTIAL], mauto = opt)\n",
    "\n",
    "gp.varmod(var_Z, mod_Z, flagLegend=True)\n",
    "gp.decoration(title = \"Variogram of the discretized variable\")\n",
    "\n",
    "mod_Z.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5fad77",
   "metadata": {},
   "source": [
    "#### Variograms of the Indicator variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4704eab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.clearLocators(gl.ELoc.Z)\n",
    "data.setLocator(\"Indicator.Z.Class*\", gl.ELoc.Z)\n",
    "\n",
    "var_Z = gl.Vario.computeFromDb(varioParam, data)\n",
    "\n",
    "mod_Z = gl.Model()\n",
    "err = mod_Z.fit(var_Z, [gl.ECov.NUGGET, gl.ECov.EXPONENTIAL, gl.ECov.EXPONENTIAL], mauto = opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbe970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp.varmod(var_Z, mod_Z)\n",
    "gp.decoration(title = \"Simple and cross variograms of the indicators of Z\", fontsize=20)\n",
    "gp.geometry(dims=(15,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6171bc06",
   "metadata": {},
   "source": [
    "The indicators are spatially correlated. A method for disjunctive kriging would consist in cokriging all indicators. Instead, we will decompose them into factors that are not correlated spatially, so that they can all be estimated seperately by kriging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a790c218",
   "metadata": {},
   "source": [
    "## MAF : Min/Max Autocorrelation Factors\n",
    "\n",
    "Indicators are decomposed on factors called MAF (Min/Max Autocorrelation Factors). MAFs are not correlated spatially, and the first MAFs represent the spatial structures with the most continuity.\n",
    "\n",
    "#### Computing MAFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0955cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.clearLocators(gl.ELoc.Z)\n",
    "data.setLocator(\"Indicator.Z.Class*\", gl.ELoc.Z)\n",
    "\n",
    "maf_I = gl.PCA()\n",
    "maf_I.maf_compute_interval(data, hmin=0.045, hmax=0.055)\n",
    "maf_I.display()\n",
    "\n",
    "#extract matrices of conversion between factors and indicators\n",
    "#Mz2f = np.reshape(maf_I.getZ2Fs(),(Nclass-1,Nclass-1)).T\n",
    "#Mf2z = np.reshape(maf_I.getF2Zs(),(Nclass-1,Nclass-1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afa2863",
   "metadata": {},
   "outputs": [],
   "source": [
    "maf_I.mafOfIndex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f96d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des maf comme fonction de l'index\n",
    "maf = np.reshape(maf_I.mafOfIndex(), (Nclass, Nclass)).T\n",
    "\n",
    "## Check that the factors are orthogonal\n",
    "tab = np.dot(np.dot(maf.T, np.diag(w)),maf).round(10)\n",
    "print(\"Correlation between factors MAF\")\n",
    "print(tab)\n",
    "\n",
    "## plot MAF as a function of the index\n",
    "fig, ax = gp.init(figsize = (10,6))\n",
    "for k in range(Nclass-1):\n",
    "    ax.plot(range(Nclass), np.sign(maf[0, k+1]) * maf[:,k+1], marker='.', label=\"MAF-\"+str(k+1))\n",
    "ax.set_xticks(range(Nclass), range(1, Nclass+1))\n",
    "ax.hlines(0, 0, Nclass-1, color='black', linestyle='dashed', linewidth=0.7)\n",
    "ax.set_xlabel(\"Indice des classes\")\n",
    "ax.set_ylabel(\"MAF\")\n",
    "l = ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d4e8f1",
   "metadata": {},
   "source": [
    "#### Visualize MAF and their variograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd51639",
   "metadata": {},
   "outputs": [],
   "source": [
    "maf_I.dbZ2F(data) # calculate MAF on the data points (new variables in data)\n",
    "\n",
    "vario_maf = gl.Vario.computeFromDb(varioParam, data)\n",
    "\n",
    "model_maf = gl.Model()\n",
    "err = model_maf.fit(vario_maf, [gl.ECov.NUGGET, gl.ECov.EXPONENTIAL, gl.ECov.EXPONENTIAL], \n",
    "                    mauto = opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62656fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp.varmod(vario_maf, model_maf)\n",
    "gp.decoration(ax, title = \"Variograms of the MAFs\", fontsize=20)\n",
    "gp.geometry(dims=(15,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ecbad8",
   "metadata": {},
   "source": [
    "# Kriging MAFs\n",
    "\n",
    "#### Define individual models for the MAFs\n",
    "\n",
    "Since the MAFs are orthogonal, we will only consider the simple variograms, in order to do kriging and not cokriging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7f1527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models of the MAFs\n",
    "\n",
    "fig, axs = gp.init(2,2, figsize=(11,7))\n",
    "\n",
    "varios, models = [], []\n",
    "for f in range(Nclass-1):\n",
    "    vario_reduced = gl.Vario(vario_maf)\n",
    "    vario_reduced.resetReduce(varcols = [f], dircols = [])\n",
    "    model = gl.Model()\n",
    "    opt=gl.Option_AutoFit()\n",
    "    opt.setWmode(0)\n",
    "    model.fit(vario_reduced, [gl.ECov.NUGGET, gl.ECov.EXPONENTIAL, gl.ECov.EXPONENTIAL], \n",
    "              mauto=opt) \n",
    "    varios.append(vario_reduced)\n",
    "    models.append(model)\n",
    "    \n",
    "    axs.flat[f].decoration(f\"Simple variogram of MAF{f+1}\")\n",
    "    axs.flat[f].varmod(vario_reduced, model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed795324",
   "metadata": {},
   "source": [
    "For example, we can obtain an estimation of the variable Z with DDK. Here we only consider the first two MAFs as an example, and because MAF3 and MAF4 are not very structured and have a very small range. MAF1 and MAF2 reprensent the pattern of the most continuity, and large scale structures.  \n",
    "First, we can do the kriging of MAF1 and MAF2 separately, as they are built to be orthogonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2161cbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define neighborhood\n",
    "neigh = gl.NeighMoving.create(nmaxi=30, radius=0.5)\n",
    "\n",
    "# Kriging MAF1\n",
    "data.setLocator(\"F*1\", gl.ELoc.Z, cleanSameLocator=True)\n",
    "gl.kriging(data, grd, models[0], neigh)\n",
    "\n",
    "# Kriging MAF2\n",
    "data.setLocator(\"F*2\", gl.ELoc.Z, cleanSameLocator=True)\n",
    "err = gl.kriging(data, grd, models[1], neigh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47baa209",
   "metadata": {},
   "source": [
    "Then, we obtain the estimate of any variable that can be expressed as a linear combination of the indicators, and that are thus also a linear combination of the MAFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9e31fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### outils de gstlearn : a ameliorer ? Ci-dessous permet de trouver l'estimation des indicatrices \n",
    "# à partir des MAFs:\n",
    "# gridData.setLocator(\"Kriging.F*.estim\", gl.ELoc.Z)\n",
    "# maf_I.dbF2Z(gridData) # estimation of the indicators\n",
    "### mais 2 manques:\n",
    " # avoir directement l'estimation d'une autre variable (ici S15), à partir des coefficient \n",
    " # de la combinaison linéaire des indicatrices\n",
    " # ne prendre en compte que les premiers MAFs (eg dans le cas où les derniers MAFs ne sont pas structurés, \n",
    " # c'est inutile de les kriger)\n",
    " # en attendant j'utilise la fonction définie ci-dessous\n",
    "\n",
    "def vecF2myvar(maf, VecF, coefs=None, mean=None, SigmaF=None):\n",
    "    \"\"\"Compute values of a variable that is a linear combination of Z variables, from vectors of factors F.\n",
    "    maf: object containing infos on the MAF computation (class PCA)\n",
    "    VecF: table containing values of the factors, shape (Ndata*NF), where NF is the number of factors used \n",
    "          (if NF is lower than the total number of factors, then only the first ones are used, \n",
    "           the others are considered not structured spatially)\n",
    "    coefs : coefficients of the variable along all variables Z\n",
    "    mean : mean of the variable.\n",
    "    SigmaF: table of the standard deviation of the estimation error of the factors, same shape as VecF. \n",
    "            If given, the standard deviation of the output variable are also computed and returned.\n",
    "    \n",
    "    eg: coefs = [1,0,0,0,0] is the first variable (indicator), with mean = 0 if not specified.\n",
    "    \"\"\"\n",
    "    VecF = np.atleast_2d(VecF)\n",
    "    Ndata, NF = VecF.shape\n",
    "    Nvar = maf.getNVar()\n",
    "    if NF < Nvar:\n",
    "        print(\"The number of factors is less than the number of variables. The other factors will be neglected.\")\n",
    "    \n",
    "    Mf2z      = maf.getF2Zs().toTL()\n",
    "    sigma     = np.array(maf.getSigmas())\n",
    "    means     = np.array(maf.getMeans())\n",
    "    mean_N    = 1 - np.sum(means)\n",
    "    coefs     = np.atleast_2d(coefs).T # one column = coefs for 1 variable\n",
    "    \n",
    "    if len(coefs) > Nvar + 1:\n",
    "        raise ValueError(f\"Too many coefficients were given ({len(coefs)}), coefs should be of length {Nvar} or {Nvar+1}.\")\n",
    "        \n",
    "    if mean is None and len(coefs) == Nvar + 1:\n",
    "        all_means = np.array(list(means) + [mean_N])\n",
    "        mean = np.sum(coefs.T*all_means, axis=1)\n",
    "    elif mean is None:\n",
    "        raise ValueError(\"The mean of the variable should be given when only the N-1 coefficients are given.\")\n",
    "    \n",
    "    if len(coefs) == Nvar:\n",
    "        c_N = 1/mean_N*(mean - np.sum(coefs.T*means, axis=1))\n",
    "        coefs = np.append(coefs, np.atleast_2d(c_N).T, axis=1) # add c_N\n",
    "    if len(coefs) != Nvar + 1:\n",
    "        print(\"Wrong len for coefs : \", len(coefs))\n",
    "    \n",
    "    Vweights = (sigma*(coefs[:-1] - coefs[-1]).T).T # w_i = (c_i - c_N)*sigma_i\n",
    "    M = np.dot(Mf2z[:NF,:], Vweights)\n",
    "    VecMyvar = np.dot(VecF, M) + mean\n",
    "    \n",
    "    if SigmaF is not None:\n",
    "        VecSigmaMyvar = np.sqrt(np.dot(SigmaF**2, M**2))\n",
    "        return np.squeeze(VecMyvar), VecSigmaMyvar.squeeze()\n",
    "    else:\n",
    "        return VecMyvar.squeeze()\n",
    "\n",
    "# extract values of the first two MAFs (the other ones have only nugget effect)\n",
    "grd.useSel=True\n",
    "VecMAF   =  grd[\"Kriging.F.*.estim\"]\n",
    "SigmaMAF =  grd[\"Kriging.F.*.stdev\"]\n",
    "\n",
    "# estimation of the indicators\n",
    "INDestim, INDstdev = vecF2myvar(maf_I, VecMAF, coefs=np.eye(5), SigmaF=SigmaMAF)\n",
    "for i_indicator in range(5):\n",
    "    grd[f\"Kriging.Indicator{i_indicator+1}.estim\"] = INDestim[:,i_indicator]\n",
    "    \n",
    "# estimation of S15\n",
    "mean_per_class = np.unique(data[\"*Mean\"])\n",
    "Zestim, Zstdev = vecF2myvar(maf_I, VecMAF, coefs=mean_per_class, SigmaF=SigmaMAF, mean=np.mean(data['Z']))\n",
    "\n",
    "grd[\"Kriging.Z.estim\"] = Zestim # Z*\n",
    "grd[\"Kriging.Z.stdev\"] = Zstdev # standard deviation of the estimation error Var(Z*-Z) = S\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca114382",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = gp.init(1,2, figsize=(10,5))\n",
    "axs[0].raster(grd,\"Kriging.F*1.estim\")\n",
    "axs[0].decoration(title='Estimation of MAF1')\n",
    "axs[1].raster(grd,\"Kriging.F*2.estim\")\n",
    "axs[1].decoration(title='Estimation of MAF2')\n",
    "\n",
    "fig, axs = gp.init(1,3, figsize=(15,5))\n",
    "axs[0].raster(grd,\"Z\")\n",
    "axs[0].decoration(title='Initial Variable Z')\n",
    "axs[1].raster(grd,\"Kriging.Z.estim\")\n",
    "axs[1].decoration(title='Estimation of Z with DDK')\n",
    "axs[2].raster(grd,\"Kriging.Z.stdev\")\n",
    "axs[2].decoration(title='Standard deviation of kriging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a3a829",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
