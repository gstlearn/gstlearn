{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrete Disjunctive Kriging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gstlearn as gl\n",
    "import gstlearn.plot as gp\n",
    "\n",
    "# initialisation\n",
    "flagKriging  = True\n",
    "flagModeling = True\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation of a reference data set\n",
    "We create a reference data set (lognormal distribution) based on a model that we define, using *simtub* (based on Turning Bands)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for the simulation\n",
    "m   = 1.\n",
    "sig = 0.5\n",
    "\n",
    "# initialization of the grid\n",
    "grd = gl.DbGrid.create(x0=(0.0,0.0), dx=(0.01,0.01), nx=(100,100))\n",
    "\n",
    "# construct a model\n",
    "model = gl.Model.createFromDb(grd)\n",
    "model.addCov(gl.CovAniso(gl.ECov.EXPONENTIAL,0.2, 0, 1., model.getContext()))\n",
    "\n",
    "# simulation of the model on the grid\n",
    "gl.simtub(dbin = None, dbout = grd, model = model, nbsimu = 1)\n",
    "grd.setName(\"Simu\", \"Y\")\n",
    "Z = m * np.exp(sig * grd[\"Y\"].squeeze() - sig**2 / 2) # transform the variable\n",
    "grd[\"Z\"] = Z\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize=(15,6))\n",
    "grd.plot(name = \"Z\", ax=ax1)\n",
    "grd.plot_hist('Z', xlab = \"Raw variable\", bins = 25, color=\"orange\", ax=ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data set\n",
    "Np = 1000 # number of samples wanted in the data set\n",
    "nech = grd.getSampleNumber()\n",
    "sel = np.zeros(nech, dtype=bool)\n",
    "sel[np.random.choice(nech, size = Np, replace = False)] = True # select randomly Np samples\n",
    "data = gl.Db(grd) # copy of grd into a Db (not gridded)\n",
    "data.addSelection(np.double(sel), \"sel\")\n",
    "\n",
    "ax = grd.plot(\"Z\", figsize=(6,6))\n",
    "ax = data.plot(size_name=\"Z\", ax=ax, color='yellow')\n",
    "ax.set_aspect(\"equal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elementary statistics\n",
    "\n",
    "We define cutoffs values corresponding to quantiles 0\\%, 30\\%, 50\\%, 70\\% and 90\\%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zcut = np.quantile(data['Z'], q = [0, 0.3, 0.5, 0.7, 0.9])\n",
    "\n",
    "print(\"\\n{:^40}\".format(\"Coupures sur la variable Z\"))\n",
    "print(\"{:^10}{:^10}{:^10}{:^10}{:^10}\".format(0., 0.3, 0.5, 0.7, 0.9))\n",
    "print(\"{:^10.3f}{:^10.3f}{:^10.3f}{:^10.3f}{:^10.3f}\".format(*zcut),'\\n')\n",
    "\n",
    "mylimits = gl.Limits(zcut) #defines limits based on the cutoff values (4 intervals delimited by the 5 cutoff values)\n",
    "mylimits.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discretization of the variable on cutoff values\n",
    "\n",
    "From the cutoff values defined above, the variable *Z* is discretized on the four intervals delimited by the cutoff values. The indicators of the intervals are $\\mathbb{1}(z_i \\le Z < z_{i+1})$. The fifth indicator ($\\mathbb{1}(Z \\ge z_{5})$) is not computed because it can be deducted from the four other ones as their sum equals to one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate \"Z\" variable\n",
    "data.clearLocators(gl.ELoc.Z)\n",
    "data.setLocator(\"Z\", gl.ELoc.Z)\n",
    "\n",
    "# Compute the indicators\n",
    "mylimits.toIndicator(data, name='Z', OptionIndicator=1) # create 4 new indicator variables\n",
    "\n",
    "# Compute the discretized version of the variable\n",
    "data.clearLocators(gl.ELoc.Z)\n",
    "data.setLocator(\"Z\", gl.ELoc.Z)\n",
    "mylimits.toIndicator(data, name='Z', OptionIndicator=0) # create the discretized variable \n",
    "\n",
    "# statistics on the indicators\n",
    "w = data.statistics([\"Indicator.Z.Class*\"], [\"mean\"], True, True, False)\n",
    "w = list(w) + [1 - np.sum(w)]\n",
    "print(\"\\nProportions:\",w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem\n",
    "function *Limits.toIndicator* does not work as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)\n",
    "\n",
    "fig, axs = plt.subplots(2,2)\n",
    "for i,ax in enumerate(axs.flatten()):\n",
    "    data.plot(f\"I*{i+1}\", ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.deleteColumn(\"Indicator*\")\n",
    "\n",
    "means = np.empty(4)               # mean per class\n",
    "DZ = np.empty(len(Z))             # discretized variable\n",
    "I5 = np.ones(len(Z), dtype=bool)  # fifth indicator, deduced from the four first ones\n",
    "for i in range(4):\n",
    "    I = (Z>=zcut[i])*(Z<zcut[i+1])         # indicator\n",
    "    data[f\"Indicator.Z.Class.{i+1}\"] = I   \n",
    "    means[i] = np.mean(Z[I])               # mean of the class\n",
    "    DZ[I] = means[i]                       # fill the discretized variable for this class\n",
    "    I5[I] = False                          # I5 is 0 where other indicators are 1\n",
    "\n",
    "DZ[I5] = np.mean(Z[I5])        # fill the discretized variable for the fifth indicator\n",
    "data[\"Indicator.Z.Mean\"] = DZ  \n",
    "\n",
    "# plot indicators\n",
    "fig, axs = plt.subplots(2,2)\n",
    "for i,ax in enumerate(axs.flatten()):\n",
    "    data.plot(f\"I*{i+1}\", ax=ax)\n",
    "# plot discretized variable\n",
    "data.plot(\"*Mean\", title='Discretized variable')\n",
    "\n",
    "# statistics on the indicators\n",
    "w = data.statistics([\"Indicator.Z.Class*\"], [\"mean\"], True, True, False)\n",
    "w = list(w) + [1 - np.sum(w)]\n",
    "print(\"\\nProportions:\",w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variography (omnidirectional)\n",
    "\n",
    "#### Variogram of the raw variable *Z*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate Z\n",
    "data.clearLocators(gl.ELoc.Z)\n",
    "data.setLocator(\"Z\", gl.ELoc.Z)\n",
    "\n",
    "# Variogram parameters\n",
    "dirParam = gl.DirParam(2, 10, 0.05) #ndim, nlags, lag\n",
    "varioParam = gl.VarioParam()\n",
    "varioParam.addDir(dirParam)\n",
    "\n",
    "var_Z = gl.Vario(varioParam, data)\n",
    "err = var_Z.compute()\n",
    "\n",
    "# fit model\n",
    "mod_Z = gl.Model()\n",
    "opt=gl.Option_AutoFit()\n",
    "opt.setWmode(2) # weighted proportional to the number of pairs and inverse proportional to the distance\n",
    "mod_Z.fit(var_Z, [gl.ECov.NUGGET, gl.ECov.EXPONENTIAL, gl.ECov.EXPONENTIAL], mauto = opt)\n",
    "\n",
    "# plot\n",
    "ax = gp.varmod(var_Z, mod_Z, title = \"Z (initial)\", flagLegend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variogram of the discretized variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.clearLocators(gl.ELoc.Z)\n",
    "data.setLocator(\"Indicator.Z.Mean\", gl.ELoc.Z)\n",
    "\n",
    "var_Z = gl.Vario(varioParam, data)\n",
    "err = var_Z.compute()\n",
    "\n",
    "mod_Z = gl.Model()\n",
    "mod_Z.fit(var_Z, [gl.ECov.NUGGET, gl.ECov.EXPONENTIAL, gl.ECov.EXPONENTIAL], mauto = opt)\n",
    "\n",
    "ax = gp.varmod(var_Z, mod_Z, title = \"Z (initial)\", flagLegend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variograms of the Indicator variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.clearLocators(gl.ELoc.Z)\n",
    "data.setLocator(\"Indicator.Z.Class*\", gl.ELoc.Z)\n",
    "\n",
    "var_Z = gl.Vario(varioParam, data)\n",
    "err = var_Z.compute()\n",
    "\n",
    "mod_Z = gl.Model()\n",
    "mod_Z.fit(var_Z, [gl.ECov.NUGGET, gl.ECov.EXPONENTIAL, gl.ECov.EXPONENTIAL], mauto = opt)\n",
    "\n",
    "ax = gp.varmod(var_Z, mod_Z, flagLegend=False, figsize=(10,10))\n",
    "plt.suptitle(\"Z (initial)\", fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The indicators are spatially correlated. A method for disjunctive kriging would consist in cokriging all indicators. Instead, we will decompose them into factors that are not correlated spatially, so that they can all be estimated seperatel by kriging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAF : Min/Max Autocorrelation Factors\n",
    "\n",
    "Indicators are decomposed on factors called MAF (Min/Max Autocorrelation Factors). MAFs are not correlated spatially, and the first MAFs represent the spatial structures with the most continuity.\n",
    "\n",
    "Definition of interval function *model.maf.index*:\n",
    "\n",
    "- on ne peux pas visualiser le premier MAF est s'assurer qu'il est monotone.\n",
    "- l'object pca a bien une fonction pca.plot mais pas de fonction spécifique pour représenter les facteurs comme des fonctions ? (à définir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des maf comme fonction de l'index\n",
    "def model_maf_index(maf, flag_interval = True):\n",
    "    if flag_interval:\n",
    "        # Calcul de la probabilité des N+1 classes\n",
    "        fw = list(maf.mean) + [1-np.sum(maf.mean)]\n",
    "        # Normalisation de l'indicatrices des intervalles\n",
    "        i_norm_val = np.eye(len(fw))\n",
    "        for i in range(len(fw)):\n",
    "            i_norm_val[:,i] = (i_norm_val[:,i] - fw[i]) / np.sqrt(fw[i]*(1-fw[i]))\n",
    "    else:\n",
    "        # Calcul de la moyenne des N+1 coupures\n",
    "        fw = [1] + list(maf.mean)\n",
    "        # Normalisation de l'indicatrices des intervalles\n",
    "        i_norm_val = np.tril(np.ones((len(fw), len(fw)))) # lower triangular matrix with ones\n",
    "        for i in range(1, len(fw)):\n",
    "            i_norm_val[:,i] = (i_norm_val[:,i] - fw[i]) / np.sqrt(fw[i]*(1-fw[i]))\n",
    "    \n",
    "    # Conversion des indicatrices normalisées en valeur des facteurs\n",
    "    maf_index = i_norm_val[:,:len(fw)-1] * maf.pcaz2f\n",
    "    return maf_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
