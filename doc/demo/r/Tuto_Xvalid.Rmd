---
title: "Xvalid"
author: "Meryem Meziane and Xavier Freulon"
date: '2023-11-30'
output:
  html_document: default
  pdf_document: default
editor_options: 
  chunk_output_type: console
---

loading libraries
```{r}
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls())
library(gstlearn)

set.seed(43243)
opers = EStatOption_fromKeys(c("NUM","MINI","MAXI","MEAN","STDV"))
```

This script demonstrates the capabilities of the cross-validation feature in gstlearn 

A fictitious data set is generated by sampling a given simulation. Then it is used to demonstrate the cross-validation tool.

A data set is first generated, composed of a series of a few samples scattered randomly within a 100 by 100 square. The number of samples is set to a small number, so as to make the results more legible. However, it could be raised to a higher value to see better results (say, 100 - but note that large numbers should be avoided since the test is performed for a unique neighborhood). In that case, the variable turnPrintON below may be switched off to avoid generating tedious printouts. 

generating the data set 
```{r}
nech = 10
turnPrintON = TRUE

data = Db_createFromBox(nech, # number of samples 
                        coormin = c(0,0), 
                        coormax = c(100,100))

# Plotting the sampling locations generated 
plot.init()+
  plot.symbol(db = data, 
             color = "red",
             size = 0.5) +
  plot.decoration(title = "Sampling locations")
```

A spherical model is defined, with the universality condition and a non conditional simulation is performed at the sampling locations. The values generated, renamed as "data", will from now on constitute the data set. 

```{r}
model = Model_createFromParam(type = ECov_SPHERICAL(), range = 30, sill = 4)
model$setDriftIRF(0)
err = simtub(NULL,
             data,
             model = model)
data$setName("Simu","data")
data

plot.init()+
  plot.symbol(data, nameSize="data",
             color = "red")+
  plot.decoration(title = "Measurement values")

```

Now cross-validation is performed. This requires the definition of a neighborhood, chosen to be unique due to the small number of samples. If necessary, a moving neighborhood could be used.

```{r}
neigh = NeighUnique()
err = xvalid(db = data,
             model = model, 
             neigh = neigh,
             flag_xvalid_est=1,
             flag_xvalid_std=1,
             namconv=NamingConvention("Xvalid",TRUE,TRUE,FALSE))
```

The cross-validation feature offers several types of outputs, according to the flags:
* flag_xvalid_est indicates if the function must return the estimation error Z-Z (flag_xvalid_est=1) or the estimation Z per se (flag_xvalid_est=-1)
* flag_xvalid_std indicates if the function must return the normalized error (Z*-Z)/S (flag_xvalid_std=1) or the standard deviation S (flag_xvalid_std=-1)

For a complete demonstration, all options are used. Note the use of NamingConvention which explicitly maintains the Z locator on the input variable (= "data"). 

The cross-validation is performed again, but the storing option is changed, as well as the radix given to the output variables.

```{r}
err = xvalid(db = data,
             model = model,
             neigh = neigh,
             flag_xvalid_est=-1, 
             flag_xvalid_std=-1,
             namconv=NamingConvention("Xvalid2",TRUE, TRUE, FALSE))
data
```

Checking the results gathered on the first sample

```{r}
data[1,0:8]
```

The printed values correspond to the following information:
* the sample rank : 1
* the sample abscissa X : 22.7
* the sample y-coordinate Y : 83.6
* the data value Z : 2.5
* the cross-validation error Z*-Z : -1.952
* the standardized cross-validation error Z∗−Z/S : -1.095
* the cross-validation estimated value Z∗ : 0.550
* the standard deviation of the cross-validation error S : 1.781

These results can also be double-checked by requesting a full dump of all the information when processing the first sample. The next chunk doesn't store any result : it simply produces an output on the terminal to better understand the process. 

```{r}
if (turnPrintON){
  OptDbg_setReference(1)
    err = xvalid(data,
                    model = model,
                    neigh = neigh,
                    flag_xvalid_est=1, 
                    flag_xvalid_std=1,
                    namconv=NamingConvention("Xvalid3",TRUE, TRUE, FALSE))
  OptDbg_setReference(0)
}
```

It appears that : 
* the cross-validation system is dimensionned to 40. Actually, for a unique neighborhood, the kriging system is established with the whole data set. The one suppressing one datum in turn is derived using the Schur theorem. 
* the result reminds the value of the measurement (2.502), the estimated value (0.550) the standard deviation of the estimation error (1.782) and the cross-validation estimation error (-1.952). 

The result can also be checked using a moving neighborhood which has been tuned to cover a pseudo-unique neighborhood. 

```{r}
neighM = NeighMoving_create()

if (turnPrintON){
  OptDbg_setReference(1)
  err = xvalid(db = data,
               model = model,
               neigh = neighM,
               flag_xvalid_est = 1,
               flag_xvalid_std = 1,
               namconv = NamingConvention("Xvalid4, TRUE, TRUE, FALSE"))
  OptDbg_setReference(0)
}
```

The next chunk displays the graphic outputs expected following a cross-validation process. They are provided by the function draw.xvalid, which produces :
* the base map of the absolute value of the standardized cross-validation error 
* the histogram of the standardized cross-validation error
* the scatter plot of the standardized error as a function of the estimate 
* the scatter plot of the real value as a function of the estimate.

```{r}
# plotting absolute value of the standardized error
plot.init()+
  plot.symbol(data,
             nameSize = "Xvalid.data.stderr", 
             color = "red",
             flagAbsSize = TRUE)+
  plot.decoration(title="Standardized error (absolute value)")

# plotting standardized error
plot.init()+
  plot.symbol(data,
             nameSize = "Xvalid.data.stderr", 
             color = "blue",
             flagAbsSize = FALSE)+
  plot.decoration(title = "Standardized error")

# plotting the histogram of the standardized error 
plot.init()+
  plot.hist(data,
            name = "Xvalid.data.stderr", 
            bins=30,
            color = "cornflowerblue",
            fill="cyan")+
  plot.decoration(xlab="Estimation Error", title="Cross-Validation")

# plotting the correlation between the estimate and the standardized error
plot.init()+
  plot.correlation(data,
                   namex = "Xvalid2.data.estim", 
                   namey = "Xvalid.data.stderr",
                   asPoint = TRUE)+
  plot.decoration(title = "Cross-Validation",
                  xlab = "kriging estimate",
                  ylab = "kriging error") 

# plotting the correlation between the estimate and the standardized error
plot.init()+
  plot.correlation(data,
                   namex = "Xvalid2.data.estim", 
                   namey = "data",
                   flagRegr = TRUE,
                   regrColor = "purple",
                   asPoint = TRUE,
                   flagSameAxes = TRUE)+
  plot.decoration(title = "Cross-Validation",
                  xlab = "kriging estimate",
                  ylab = "measured values") 
```

# K-Fold cross-validation

## Data set

'dbin' contains scattered points.

Note: the K-fold cross validation is not available for a unique neighborhood.

```{r}
N     = 300
K     = 10
dbin  = Db_createFillRandom(ndat = N, nvar = 0, seed = 125)
dbin["folds"] = sample(1:K, size = dbin$getNSample(TRUE), replace = TRUE)
p <- plot.init() +
  plot.symbol(dbin,  nameColor = "folds", palette = "Spectral", 
             flagLegend = TRUE, legendNameColor = "Folds") +
  plot.decoration(xlab = "X", ylab = "Z", title = "Simulated Folds")
plot.end(p)
```

We define a Model and simulate the variable at sample locations.

```{r}
model = Model()
err = model$addCovFromParam(type = ECov_EXPONENTIAL(), range = 0.2,  sill = 1)
err = model$setDriftIRF(0,0)

err = simtub(dbin = NULL, dbout = dbin, model = model, nbsimu = 1, seed = 235, nbtuba = 1000, 
             namconv = NamingConvention("Y"))
```

We define a (Moving) neighborhood

```{r}
neigh = NeighMoving_create(nmini = 10, nmaxi = 10)
```

We perform the cross-validation (using Ordinary Kriging) without the folds: it is based on the Leave-One-Out algorithm..

```{r}
err = dbin$deleteColumns(names = "*.xval.*")

err = dbin$setLocators("Y", locatorType = ELoc_Z(), cleanSameLocator = TRUE)
err = xvalid(
  db = dbin, model = model, neigh = neigh, flag_kfold = FALSE,
  flag_xvalid_est = 1, flag_xvalid_std = 1,
  namconv = NamingConvention("OK.xval.LOO")
)
```

We now perform the same task but with K-Fold option

```{r}
err = dbin$setLocators("Y", locatorType = ELoc_Z(), cleanSameLocator = TRUE)
err = dbin$setLocator("folds", locatorType = ELoc_C(), cleanSameLocator = TRUE)
err = xvalid(
  db = dbin, model = model, neigh = neigh, flag_kfold = TRUE,
  flag_xvalid_est = 1, flag_xvalid_std = 1,
  namconv = NamingConvention("OK.xval.kfold")
)
```

```{r}
knitr::kable(dbStatisticsMono(dbin, names = c("Y", "OK.xval.LOO.Y.*", "OK.xval.kfold.Y.*"), 
                              opers = opers)$toTL(),
             digits = 3, caption = paste0("Cross validation scores (K  = ", K, ")"))
```

```{r}
p1 <- plot.init() +
  plot.hist(dbin,  name = "OK.xval.LOO.Y.stderr", bins = 20, fill = "orange") +
  plot.decoration(xlab = "Normalised estimation error (Z*-Z)/S", 
                  title = "Leave-One-Out cross validation")

p2 <- plot.init() +
  plot.hist(dbin,  name = "OK.xval.kfold.Y.stderr", bins = 20, fill = "skyblue") +
  plot.decoration(xlab = "Normalised estimation error (Z*-Z)/S", 
                  title = paste0("K-fold cross validation (K = ", K, ")"))

ggarrange(p1, p2, nrow = 1, ncol = 2)
```
