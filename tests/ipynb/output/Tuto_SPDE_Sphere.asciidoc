#NO_DIFF#XXX
----<IPython.core.display.Javascript object>----


#NO_DIFF#XXX
----
<style>md-block { color:gray; background-color:white; }</style><md-block>
**SPDE on the Sphere**

The aim of this tutorial is to show how to use gstlearn to simulate the solution of 

$$(\kappa^2-\Delta_{\mathcal{S}_R})^{\alpha/2}Z = \sigma\mathcal{W}$$

on the sphere $\mathcal{S}_R$ of radius $R$.

- $\Delta_{{\mathcal{S}_R}}$ is the Laplace-Beltrami operator, i.e, it acts on each point of the sphere as the usual Laplacian on the tangent plane at this point. 

- $\kappa$ is the inverse of the scale parameter

- $\alpha \geq 2$ is an integer describing the smoothness of the solution.

- $\mathcal{W}$ is a Gaussian white-noise suitably normalized such as $\sigma^2$ is the variance of the solution.

In this notebook, we will define the covariance of Matérn on the sphere, as the covariance of the solution of this SPDE (other extensions of the Matérn function are possible). By analogy with the Euclidian case, its smoothness parameter will be defined by $\nu = \alpha -1$. To compute the covariance function with respect on the geodetic distance, one have to use a decomposition on the Legendre polynomial (see below).

We also treat the more general case
$$P^{1/2}(-\Delta_{\mathcal{S}_R})Z = \sigma\mathcal{W}$$

where $P$ is a polynom positive on $\mathbb{R}^+$</md-block>
----


#NO_DIFF#XXX
----



----


#NO_DIFF#XXX
----
Discretized Covariance = 2.0393
----


#NO_DIFF#XXX
----
Discretized variance = 2.0393

#NO_DIFF#XXX
----


#NO_DIFF#XXX
----
#NO_DIFF#XXX
----


#NO_DIFF#XXX
----
<style>md-block { color:gray; background-color:white; }</style><md-block>
**Covariance on the Sphere**

The covariance between two points with great-circle distance $d$  on the sphere of radius $R$ is given by
$$C(d) = \frac{\sigma^2}{\sum_{i=0}^\infty f(i)}\sum_{i=0}^\infty f(i) P_i\left(\cos \frac{d}{R}\right)$$

where the $P_i$'s  are the Legendre polynomials computed with the following reccurence formula

$$P_0(x) = 1.$$

$$P_1(x) = x$$

$$P_{n+1}(x)=\frac{(2n+1)xP_n(x) - n P_{n-1}(x)}{n+1}$$

For $n\geq 0$, $$f(n) = \frac{2n+1}{ (R^2\kappa^2 + n ( n + 1))^\alpha}$$

For numerical computations, the sums are truncated at **N**.

For more details on the covariances on sphere, see 
[Lantuejoul, Freulon and Renard (2019)](https://link.springer.com/content/pdf/10.1007/s11004-019-09799-4.pdf)
</md-block>
----


#NO_DIFF#XXX
----
#NO_DIFF#XXX
----


#NO_DIFF#XXX
----
#NO_DIFF#XXX

Theoretical variance = 1.9943
----


#NO_DIFF#XXX
----
Data Base Characteristics
=========================

Data Base Summary
-----------------
File is organized as a set of isolated points
Space dimension              = 2
Number of Columns            = 5
Total number of samples      = 4000

Variables
---------
Column = 0 - Name = x - Locator = x1
Column = 1 - Name = y - Locator = x2
Column = 2 - Name = sizes - Locator = NA
Column = 3 - Name = colors - Locator = NA
Column = 4 - Name = simu - Locator = z1----


#NO_DIFF#XXX
----

----


#NO_DIFF#XXX
----

Ball Tree
=========
- Number of samples = 320
- Number of Features = 2
- Number of levels = 5
- Number of nodes = 31
- Size of leaf = 10
----


#NO_DIFF#XXX
----

----


#NO_DIFF#XXX
----

----


#NO_DIFF#XXX
----

Vertices used in the projection matrix
--------------------------------------
(Display is limited to 30 samples)
Sample   0:   94 [ 0.37]  96 [ 0.50] 141 [ 0.12]
Sample   1:   24 [ 0.38]  83 [ 0.50] 110 [ 0.12]
Sample   2:   45 [ 0.25] 111 [ 0.12] 146 [ 0.62]
Sample   3:  109 [ 0.37] 133 [ 0.25] 144 [ 0.38]
Sample   4:   44 [ 0.13]  95 [ 0.25] 121 [ 0.62]
Sample   5:   31 [ 0.62] 143 [ 0.38]
Sample   6:   60 [ 0.25] 126 [ 0.50] 138 [ 0.25]
Sample   7:   91 [ 0.13] 108 [ 0.75] 113 [ 0.13]
Sample   8:   37 [ 0.50] 116 [ 0.25] 133 [ 0.25]
Sample   9:   55 [ 0.25]  79 [ 0.25]  81 [ 0.50]
Sample  10:    8 [ 0.62]  96 [ 0.25] 141 [ 0.12]
Sample  11:  116 [ 0.62] 133 [ 0.12] 148 [ 0.25]
Sample  12:   27 [ 0.12]  74 [ 0.25] 158 [ 0.62]
Sample  13:    5 [ 0.37]  27 [ 0.50] 101 [ 0.13]
Sample  14:  138 [ 1.00]
Sample  15:    5 [ 0.62]  27 [ 0.25]  56 [ 0.13]
Sample  16:   75 [ 0.00] 114 [ 0.75] 118 [ 0.25]
Sample  17:   44 [ 0.38]  95 [ 0.62] 121 [ 0.00]
Sample  18:   32 [ 0.62]  75 [ 0.38]
Sample  19:   25 [ 0.12]  30 [ 0.25]  66 [ 0.63]
Sample  20:   52 [ 0.37]  54 [ 0.50]  97 [ 0.12]
Sample  21:  125 [ 0.00] 142 [ 0.37] 161 [ 0.63]
Sample  22:   46 [ 0.13] 105 [ 0.75] 137 [ 0.13]
Sample  23:   16 [ 0.25]  19 [ 0.37]  57 [ 0.38]
Sample  24:    1 [ 0.12]  51 [ 0.12]  76 [ 0.75]
Sample  25:    3 [ 0.25]  63 [ 0.12]  83 [ 0.63]
Sample  26:    3 [ 0.38]  12 [ 0.37]  24 [ 0.25]
Sample  27:   10 [ 0.25]  23 [ 0.62]  51 [ 0.13]
Sample  28:   28 [ 0.50]  68 [ 0.12]  94 [ 0.37]
Sample  29:   52 [ 0.25]  67 [ 0.75]
----
