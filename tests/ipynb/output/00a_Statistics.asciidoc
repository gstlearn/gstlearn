#NO_DIFF#XXX
----<IPython.core.display.Javascript object>----


#NO_DIFF#XXX
----

|===
| |Longitude |Latitude |Elevation |January_temp
|0 |372.1 |658.9 |255 |1.7
|1 |303.5 |665.9 |125 |2
|2 |218.4 |597.9 |8 |4.6
|3 |245.0 |955.0 |90 |MISS
|4 |326.8 |691.2 |32 |3.1
|... |... |... |... |...
|231 |273.2 |564.6 |47 |2.8
|232 |333.9 |730.1 |30 |2.6
|233 |185.0 |655.0 |115 |MISS
|234 |259.8 |587.9 |119 |2.1
|235 |260.8 |668.6 |107 |2.6
|===

236 rows × 4 columns
----


#NO_DIFF#XXX
----
#### Mean

latexmath:[\[\bar{z} = \frac{1}{n}\sum_{i=1}^n z_i\]]
----


#NO_DIFF#XXX
----
Mean = 146.44
----


#NO_DIFF#XXX
----
#### Median

The median latexmath:[$m$] of the set of values is a value such as half
of the total observations are below and half is above.

* If the size latexmath:[$n$] is odd, it is the value of the
latexmath:[$z_{\left(\frac{n+1}{2}\right)}$] where latexmath:[$z_{(i)}$]
is the value of the latexmath:[$i$] th observation (when ordered in
increasing order).
* If latexmath:[$n$] is even, we can take
latexmath:[$\frac{z_{\left(\frac{n}{2}\right)}+z_{\left(\frac{n}{2}+1\right)}}{2}$].

The median is less sensitive than the mean to extreme values.
----


#NO_DIFF#XXX
----
Median = 85.5
----


#NO_DIFF#XXX
----
#### Quartiles

The quartiles are the values which divide the samples as follows:

* lower quartile: 25% of the individuals are below
* upper quartile: 25% of the individuals are above
----


#NO_DIFF#XXX
----
Quartiles = [  2.    28.5   85.5  216.25 800.  ]
----


#NO_DIFF#XXX
----
#### Quantiles (p)

We can generalize to any proportion latexmath:[$p$].

The latexmath:[$p-$]quantile denoted latexmath:[$q_p$] is a value which
divides the samples such as a proportion latexmath:[$p$] of the
individuals are below the quantile.

The median is latexmath:[$q_{\frac{1}{2}}$]. The lower quartile is
latexmath:[$q_{\frac{1}{4}}$] and the upper quartile is
latexmath:[$q_{\frac{3}{4}}$].
----


#NO_DIFF#XXX
----
#### Range

latexmath:[\[\max_{i=1,\dots,n}{z_i}-\min_{i=1,\dots,n}{z_i}\]]
----


#NO_DIFF#XXX
----
Range= 798
----


#NO_DIFF#XXX
----
#### Inter-quartiles distance

latexmath:[\[q_{\frac{3}{4}}-q_{\frac{1}{4}}\]]
----


#NO_DIFF#XXX
----
Inter-quartiles distance = [187.75]
----


#NO_DIFF#XXX
----
#### Variance

The variance measures the average distance between each individual to
the mean:

latexmath:[\[\frac{1}{n}\sum_{i=1}^n(z_i-\bar{z})^2\]]

It is sometimes more convenient to use the equivalent formula

latexmath:[\[\frac{1}{n}\sum_{i=1}^nz_i^2-\bar{z}^2 = \bar{z^2}-\bar{z}^2\]]

Note that for statistical reasons, one often prefers to use

latexmath:[\[\frac{1}{n-1}\sum_{i=1}^n(z_i-m)^2\]]

for the variance. The two formulas give close results when
latexmath:[$n$] is large.
----


#NO_DIFF#XXX
----
Variance (First formula) = 27270.71258259121
Variance (Sec.  formula) = 27270.712582591204
Variance (numpy version) = 27270.71258259121
----


#NO_DIFF#XXX
----
#### Standard Deviation

To have a measure in the same unit as the variable, one often consider
the standard deviation.

latexmath:[\[\sqrt{\frac{1}{n}\sum_{i=1}^n(z_i-\bar{z})^2}\]]
----


#NO_DIFF#XXX
----
Variance (numpy version) = 165.13846487899545
----


#NO_DIFF#XXX
----
### Histogram

To have a good idea of the distribution of a variable, one can compute
the histogram.

The idea is

* divide the range of the variable latexmath:[$[min,Max]$] into small
intervals. Here, we only treat the case were all intervals have the same
size
* compute the number of samples in each interval.

Normalized histogram rescales the ordinate such as the total surface is
equal to 1.
----


#NO_DIFF#XXX
----
#NO_DIFF#XXX
----


#NO_DIFF#XXX
----
#NO_DIFF#XXX
----


#NO_DIFF#XXX
----
### Cumulated histogram

We can represent the cumulated histogram. It is a function which
computes, for each value, the proportion of individuals below this
value. It can be written as

latexmath:[\[F(z_c) =\frac{1}{n}\sum_{i=1}^n 1\!\!\!1_{]z_{i},+\infty]}(z_c)\]]

where latexmath:[$1\!\!\!1_A$] is the indicator function of the set
latexmath:[$A$]:

latexmath:[\[1\!\!\!1_A(x)=\left\{\begin{array}{ccc}1 &\textrm{ if } & x\in A\\
   0 & \textrm{ otherwise } & \end{array}
   \right.\]]
----


#NO_DIFF#XXX
----
#NO_DIFF#XXX
----


#NO_DIFF#XXX
----
### Quantile function

If we inverse the two axes, we obtain the quantile function which gives,
for each value latexmath:[$p$], the quantile latexmath:[$q_p$].

latexmath:[\[q(p) = F^{-1}(p)\]]
----


#NO_DIFF#XXX
----
#NO_DIFF#XXX
----


#NO_DIFF#XXX
----
### Ore

In mine, we often consider the ore function
latexmath:[\[T(z_c) = 1-F(z_c)\]]

Indeed, it gives the proportion of the data which are above a cut-off.
----


#NO_DIFF#XXX
----
#NO_DIFF#XXX
----


#NO_DIFF#XXX
----
### Metal

latexmath:[\[Q(z_c) =\frac{1}{n}\sum_{i=1}^n z_i1\!\!\!1_{]z_{i},+\infty]}(z_c)\]]
----


#NO_DIFF#XXX
----
#NO_DIFF#XXX
----


#NO_DIFF#XXX
----
### Grade

latexmath:[\[m(z_c)=\frac{Q(z_c)}{T(z_c)}\]]
----


#NO_DIFF#XXX
----
#NO_DIFF#XXX
----


#NO_DIFF#XXX
----
#### latexmath:[$Q(T)$] curve

We just represent the *Metal* with respect to the *Ore* for various
cut-off values latexmath:[$z_c$].
----


#NO_DIFF#XXX
----
#NO_DIFF#XXX
----


#NO_DIFF#XXX
----
#### Conventional benefit

latexmath:[\[B(z_c) = Q(z_c)-z_cT(z_c)\]]
----


#NO_DIFF#XXX
----
#NO_DIFF#XXX
----


#NO_DIFF#XXX
----
Now we consider two variables:

* latexmath:[$z^{(1)}=(z_1^{(1)},\dots,z_n^{(1)})$]
* latexmath:[$z^{(2)}=(z_1^{(2)},\dots,z_n^{(2)})$]

and we will study their relationship.
----


#NO_DIFF#XXX
----
### Covariance

We can compute the covariance between the two vectors
latexmath:[$z^{(1)}$] and latexmath:[$z^{(2)}$].

latexmath:[\[\textrm{cov}(z^{(1)},z^{(2)}) = \frac{1}{n}\sum_{i=1}^n (z^{(1)}_i-\bar{z}^{(1)})(z^{(2)}_i-\bar{z}^{(2)})\]]

where latexmath:[$\bar{z}^{(j)}$] is the mean of the variable
latexmath:[$z^{(j)}$] with latexmath:[$j=1,2$].
----


#NO_DIFF#XXX
----
Covariance = -72.91027814569537
----


#NO_DIFF#XXX
----
### Correlation coefficient

The covariance depends on the scale of latexmath:[$z^{(1)}$] and
latexmath:[$z^{(2)}$]. In order to have a scale invariant measure, we
can use the correlation coefficient
latexmath:[\[\rho = \frac{\textrm{cov}(z^{(1)},z^{(2)})}{\sqrt{\textrm{var}(z^{(1)})\textrm{var}(z^{(2)})}}\]]

The correlation coefficient lies within latexmath:[$[-1,1]$].

When it is equal to latexmath:[$-1$] or latexmath:[$1$], the variables
are linked by a linear relationship

latexmath:[\[z^{(2)}=a.z^{(1)}+b\]]

where the sign of latexmath:[$a$] corresponds to the sign of
latexmath:[$\rho$].

When latexmath:[$\rho=0$], we say that the variables are uncorrelated.
But they can still have a link (not linear).
----


#NO_DIFF#XXX
----
Correlation coefficient -0.8023
----


#NO_DIFF#XXX
----
### Covariance matrix

When we have several variables latexmath:[$z^{(1)},\dots,z^{(p)}$], we
can compute their covariance matrix latexmath:[$\Sigma$] which stores
the covariances between each pair of variable.

latexmath:[\[\Sigma = \left[
\begin{array}{cccc}
\textrm{var}(z^{(1)})         & \textrm{cov}(z^{(1)},z^{(2)}) &\dots  & \textrm{cov}(z^{(1)},z^{(p)})\\
\textrm{cov}(z^{(2)},z^{(1)}) & \textrm{var}(z^{(2)})         & \dots & \textrm{cov}(z^{(2)},z^{(p)})\\
\vdots & \vdots & \ddots & \vdots \\
\textrm{cov}(z^{(p)},z^{(1)}) &  \textrm{cov}(z^{(p)},z^{(2)})&\dots  & \textrm{var}(z^{(p)})\\
\end{array}\right]\]]

Note that this matrix is symmetric.

If the variables (centered by their means) are stored in a matrix
latexmath:[$Z_c$] (one column per variable), then

latexmath:[\[\Sigma = \frac{1}{n} Z_c^TZ_c\]] where latexmath:[$^T$]
designates the transposition.

In other words, latexmath:[$Z_c^T$] is the matrix where each line is a
variable.
----


#NO_DIFF#XXX
----
Covariance matrix = 
[[ 8.04385263e+03 -7.29102781e+01]
 [-7.29102781e+01  1.02658631e+00]]
----


#NO_DIFF#XXX
----
Variance 8043.852626931566
----


#NO_DIFF#XXX
----
Covariance matrix = 
[[ 7.99058208e+03 -7.24274286e+01]
 [-7.24274286e+01  1.01978773e+00]]
----


#NO_DIFF#XXX
----
### Scatter plot

We can represent the scatter plot between the two variables (only
isotopic samples are represented).
----


#NO_DIFF#XXX
----
#NO_DIFF#XXX
----


#NO_DIFF#XXX
----
Here the relation could be considered as linear. Let’s try to find the
coefficents of the regression line.

== Linear regression

=== Simple linear regression

We can model the relationship between latexmath:[$z^{(1)}$] and
latexmath:[$z^{(2)}$] by using a linear regression. model
latexmath:[\[z^{(2)}=az^{(1)}+b + R\]] where latexmath:[$R$] is a
residual.

We try to find latexmath:[$(a,b)$] by minimizing the sum of the squared
difference between latexmath:[$z^{(2)}$] and latexmath:[$az^{(1)}+b$]:

latexmath:[\[||R||^2 =\sum_{i=1}^n(z^{(2)}_i - (az^{(1)}_i+b))^2.\]]

We can show that the coefficients latexmath:[$a$] and latexmath:[$b$]
can be estimated by

latexmath:[\[\hat a = \frac{\textrm{cov}(z^{(1)},z^{(2)})}{\textrm{var}(z^{(1)})}\]]

and latexmath:[$b$] by

latexmath:[\[\hat b = \bar{z}^{(2)}-\hat a\bar{z}^{(1)}\]]
----


#NO_DIFF#XXX
----
#NO_DIFF#XXX
----


#NO_DIFF#XXX
----
#### Multiple linear regression

When we have several variables latexmath:[$x^{(1)},\dots,x^{(p)}$] to
explain an interest variable latexmath:[$y$] we can also use a linear
regression

latexmath:[\[y=\sum_{j=1}^p \beta_j x^{(j)} + \beta_0 + R\]]

Note that for convenience, we will rewrite the relation

latexmath:[\[y=\sum_{j=0}^p \beta_j x^{(j)}+R\]]

where the variable latexmath:[$x^{(0)}$] is equal to latexmath:[$1$].

Last, we can rewrite more compactly

latexmath:[\[y = \beta^T X +R\]]

where
latexmath:[\[\beta = \left[\begin{array}{c}\beta_0 \\ \vdots \\ \beta_p\end{array}\right]\]]

and latexmath:[$X$] is the table with all the observations. The first
column contains latexmath:[$1$]’s and then each column is a variable
latexmath:[\[X  = \left[\begin{array}{cccc} 1 & x^{(1)} & \dots & x^{(p)}\end{array}\right]\]]

As in the simple linear regression case, we will try to minimize

latexmath:[\[||R||^2=||y-\beta^TX||^2\]]

We can show that

latexmath:[\[\hat\beta = (X^TX)^{-1}X^Ty\]]
----


#NO_DIFF#XXX
----
### Bivariate histogram

To represent the two variables, we can perform a 2d histogram.
----


#NO_DIFF#XXX
----
#NO_DIFF#XXX
----


#NO_DIFF#XXX
----
### Conditional distribution

Then we could look at the histogram of latexmath:[$z_2$] for a given
class of latexmath:[$z_1$].

For instance, if we consider the 2latexmath:[$^\textrm{nd}$] class,
latexmath:[$z_1\in[28.6,54.2]$] :

It shows the (empirical) conditional distribution of latexmath:[$z_2$]
knowing that latexmath:[$z_1\in[28.6,54.2]$].
----


#NO_DIFF#XXX
----
#NO_DIFF#XXX
----


#NO_DIFF#XXX
----
#### Conditional mean (or regression)

In the same spirit, we can consider the conditional mean (mean of
latexmath:[$z_2$] for a given classe of latexmath:[$z_1$]). It is the
conditional mean.

If we iterate over all the classes, we obtain the empirical regression.
----


#NO_DIFF#XXX
----
#NO_DIFF#XXX
----
