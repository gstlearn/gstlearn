+#NO_DIFF#XXX+
----<IPython.core.display.Javascript object>----


+#NO_DIFF#XXX+
----
# Statistics #

== Location

=== Mean

latexmath:[\[bar{z} = \frac{1}{n}\sum_{i=1}^n z_i\]]

=== Median

The median latexmath:[$m$] of the set of values is a value such as half
of the total observations are below and half is above.

* If the size latexmath:[$n$] is odd, it is the value of the
latexmath:[$z_{\left(\frac{n+1}{2}\right)}$] where latexmath:[$z_{(i)}$]
is the value of the latexmath:[$i$] th observation (when ordered in
increasing order).
* If latexmath:[$n$] is even, we can take
latexmath:[$\frac{z_{\left(\frac{n}{2}\right)}+z_{\left(\frac{n}{2}+1\right)}}{2}$].

The median is less sensitive than the mean to extreme values.

=== Quartiles

The quartiles are the values which divide the samples as follows:

* lower quartile: 25% of the individuals are below
* upper quartile: 25% of the individuals are above

=== Quantiles (p)

We can generalize to any proportion latexmath:[$p$].

The latexmath:[$p-$]quantile denoted latexmath:[$q_p$] is a value which
divides the samples such as a proportion latexmath:[$p$] of the
individuals are below the quantile.

The median is latexmath:[$q_{\frac{1}{2}}$]. The lower quartile is
latexmath:[$q_{\frac{1}{4}}$] and the upper quartile is
latexmath:[$q_{\frac{3}{4}}$].

== Dispersion

The dispersion summaries try to measure how the data are spread.

=== Range

latexmath:[\[\max_{i=1,\dots,n}{z_i}-\min_{i=1,\dots,n}{z_i}\]]

=== Inter-quartiles distance

latexmath:[\[q_{\frac{3}{4}}-q_{\frac{1}{4}}\]]

=== Variance

The variance measures the average distance between each individual to
the mean:

latexmath:[\[\frac{1}{n}\sum_{i=1}^n(z_i-\bar{z})^2\]]

It is sometimes more convenient to use the equivalent formula

latexmath:[\[\frac{1}{n}\sum_{i=1}^nz_i^2-\bar{z}^2 = \bar{z^2}-\bar{z}^2\]]

Note that for statistical reasons, one often prefers to use

latexmath:[\[\frac{1}{n-1}\sum_{i=1}^n(z_i-m)^2\]]

for the variance. The two formulas give close results when
latexmath:[$n$] is large.

To have a measure in the same unit as the variable, one often consider
the standard deviation.

latexmath:[\[\sqrt{\frac{1}{n}\sum_{i=1}^n(z_i-\bar{z})^2}\]]

== Distribution

=== Histogram

To have a good idea of the distribution of a variable, one can compute
the histogram.

The idea is

* divide the range of the variable latexmath:[$[min,Max]$] into small
intervals. Here, we only treat the case were all intervals have the same
size
* compute the number of samples in each interval.

Normalized histogram rescales the ordinate such as the total surface is
equal to 1.

=== Cumulated histogram

We can represent the cumulated histogram. It is a function which
computes, for each value, the proportion of individuals below this
value. It can be written as

latexmath:[\[F(z_c) =\frac{1}{n}\sum_{i=1}^n 1\!\!\!1_{]z_{i},+\infty]}(z_c)\]]

where latexmath:[$1\!\!\!1_A$] is the indicator function of the set
latexmath:[$A$]:

latexmath:[\[1\!\!\!1_A(x)=\left\{\begin{array}{ccc}1 &\textrm{ if } & x\in A\\
   0 & \textrm{ otherwise } & \end{array}
   \right.\]]

=== Quantile function

If we inverse the two axes, we obtain the quantile function which gives,
for each value latexmath:[$p$], the quantile latexmath:[$q_p$].

latexmath:[\[q(p) = F^{-1}(p)\]]

=== Ore

In mine, we often consider the ore function
latexmath:[\[T(z_c) = 1-F(z_c)\]]

Indeed, it gives the proportion of the data which are above a cut-off.

=== Metal

latexmath:[\[Q(z_c) =\frac{1}{n}\sum_{i=1}^n z_i1\!\!\!1_{]z_{i},+\infty]}(z_c)\]]

=== Grade

latexmath:[\[m(z_c)=\frac{Q(z_c)}{T(z_c)}\]]

==== latexmath:[$Q(T)$] curve

We just represent the *Metal* with respect to the *Ore* for various
cut-off values latexmath:[$z_c$].

==== Conventional benefit

latexmath:[\[B(z_c) = Q(z_c)-z_cT(z_c)\]]

== Bivariate statistics

Now we consider two variables:

* latexmath:[$z^{(1)}=(z_1^{(1)},\dots,z_n^{(1)})$]
* latexmath:[$z^{(2)}=(z_1^{(2)},\dots,z_n^{(2)})$]

and we will study their relationship.

=== Covariance

We can compute the covariance between the two vectors
latexmath:[$z^{(1)}$] and latexmath:[$z^{(2)}$].

latexmath:[\[\textrm{cov}(z^{(1)},z^{(2)}) = \frac{1}{n}\sum_{i=1}^n (z^{(1)}_i-\bar{z}^{(1)})(z^{(2)}_i-\bar{z}^{(2)})\]]

where latexmath:[$\bar{z}^{(j)}$] is the mean of the variable
latexmath:[$z^{(j)}$] with latexmath:[$j=1,2$].

=== Correlation coefficient

The covariance depends on the scale of latexmath:[$z^{(1)}$] and
latexmath:[$z^{(2)}$]. In order to have a scale invariant measure, we
can use the correlation coefficient
latexmath:[\[\rho = \frac{\textrm{cov}(z^{(1)},z^{(2)})}{\sqrt{\textrm{var}(z^{(1)})\textrm{var}(z^{(2)})}}\]]

The correlation coefficient lies within latexmath:[$[-1,1]$].

When it is equal to latexmath:[$-1$] or latexmath:[$1$], the variables
are linked by a linear relationship

latexmath:[\[z^{(2)}=a.z^{(1)}+b\]]

where the sign of latexmath:[$a$] corresponds to the sign of
latexmath:[$\rho$].

When latexmath:[$\rho=0$], we say that the variables are uncorrelated.
But they can still have a link (not linear).

=== Covariance matrix

When we have several variables latexmath:[$z^{(1)},\dots,z^{(p)}$], we
can compute their covariance matrix latexmath:[$\Sigma$] which stores
the covariances between each pair of variable.

latexmath:[\[\Sigma = \left[
\begin{array}{cccc}
\textrm{var}(z^{(1)})         & \textrm{cov}(z^{(1)},z^{(2)}) &\dots  & \textrm{cov}(z^{(1)},z^{(p)})\\
\textrm{cov}(z^{(2)},z^{(1)}) & \textrm{var}(z^{(2)})         & \dots & \textrm{cov}(z^{(2)},z^{(p)})\\
\vdots & \vdots & \ddots & \vdots \\
\textrm{cov}(z^{(p)},z^{(1)}) &  \textrm{cov}(z^{(p)},z^{(2)})&\dots  & \textrm{var}(z^{(p)})\\
\end{array}\right]\]]

Note that this matrix is symmetric.

If the variables (centered by their means) are stored in a matrix
latexmath:[$Z_c$] (one column per variable), then

latexmath:[\[\Sigma = \frac{1}{n} Z_c^TZ_c\]] where latexmath:[$^T$]
designates the transposition.

In other words, latexmath:[$Z_c^T$] is the matrix where each line is a
variable.

=== Scatter plot

We can represent the scatter plot between the two variables (only
isotopic samples are represented).

Here the relation could be considered as linear. Let’s try to find the
coefficents of the regression line.

=== Linear regression

==== Simple linear regression

We can model the relationship between latexmath:[$z^{(1)}$] and
latexmath:[$z^{(2)}$] by using a linear regression. model
latexmath:[\[z^{(2)}=az^{(1)}+b + R\]] where latexmath:[$R$] is a
residual.

We try to find latexmath:[$(a,b)$] by minimizing the sum of the squared
difference between latexmath:[$z^{(2)}$] and latexmath:[$az^{(1)}+b$]:

latexmath:[\[||R||^2 =\sum_{i=1}^n(z^{(2)}_i - (az^{(1)}_i+b))^2.\]]

We can show that the coefficients latexmath:[$a$] and latexmath:[$b$]
can be estimated by

latexmath:[\[\hat a = \frac{\textrm{cov}(z^{(1)},z^{(2)})}{\textrm{var}(z^{(1)})}\]]

and latexmath:[$b$] by

latexmath:[\[\hat b = \bar{z}^{(2)}-\hat a\bar{z}^{(1)}\]]

==== Multiple linear regression

When we have several variables latexmath:[$x^{(1)},\dots,x^{(p)}$] to
explain an interest variable latexmath:[$y$] we can also use a linear
regression

latexmath:[\[y=\sum_{j=1}^p \beta_j x^{(j)} + \beta_0 + R\]]

Note that for convenience, we will rewrite the relation

latexmath:[\[y=\sum_{j=0}^p \beta_j x^{(j)}+R\]]

where the variable latexmath:[$x^{(0)}$] is equal to latexmath:[$1$].

Last, we can rewrite more compactly

latexmath:[\[y = \beta^T X +R\]]

where
latexmath:[\[\beta = \left[\begin{array}{c}\beta_0 \\ \vdots \\ \beta_p\end{array}\right]\]]

and latexmath:[$X$] is the table with all the observations. The first
column contains latexmath:[$1$]’s and then each column is a variable
latexmath:[\[X  = \left[\begin{array}{cccc} 1 & x^{(1)} & \dots & x^{(p)}\end{array}\right]\]]

As in the simple linear regression case, we will try to minimize

latexmath:[\[||R||^2=||y-\beta^TX||^2\]]

We can show that

latexmath:[\[\hat\beta = (X^TX)^{-1}X^Ty\]]

=== Regression

To represent the two variables, we can perform a 2d histogram.

Then we could look at the histogram of latexmath:[$z_2$] for a given
class of latexmath:[$z_1$].

For instance, if we consider the 3rd class,
latexmath:[$z_1\in[1.14,1.67]$] :

It shows the conditional distribution of latexmath:[$z_2$] knowing that
latexmath:[$z_1\in[1.14,1.67]$].

==== Conditional mean (or regression)

In the same spirit, we can consider the conditional mean (mean of
latexmath:[$z_2$] for different class of latexmath:[$z_1$]).

It is named conditional mean (or regression).
----
