[[demonstration-of-gstlearn-for-a-2-d-case-study]]
= Demonstration of gstlearn for a 2-D case study

[source, javascript]
----
%%javascript
IPython.OutputArea.prototype._should_scroll = function(lines) {
    return false;
}
----


----<IPython.core.display.Javascript object>----

[[import-packages]]
== Import packages

[source, ipython3]
----
import numpy as np
import pandas as pd
import sys
import os
import matplotlib.pyplot as plt
import gstlearn as gl
import gstlearn.plot as gp
----

Global variables

[source, ipython3]
----
verbose  = True
graphics = True
gl.OptCst.define(gl.ECst.NTCOL,6)
----

[[reading-data]]
== Reading data

The data are stored in a CSV format in the file called Pollution.dat

[source, ipython3]
----
dataDir = os.path.join(os.path.pardir,os.path.pardir,"doc","data","Pollution")
filepath = os.path.join(dataDir,"Pollution.dat")
mydb = gl.Db.createFromCSV(filepath,gl.CSVformat())
err = mydb.setLocators(["X","Y"],gl.ELoc.X)
err = mydb.setLocator("Zn",gl.ELoc.Z)
if verbose:
    dbfmt = gl.DbStringFormat()
    dbfmt.setParams(gl.FLAG_RESUME | gl.FLAG_EXTEND | gl.FLAG_VARS) 
    mydb.display(dbfmt)
----


----

Data Base Characteristics
=========================

Data Base Summary
-----------------
File is organized as a set of isolated points
Space dimension              = 2
Number of Columns            = 5
Maximum Number of UIDs       = 5
Total number of samples      = 102

Data Base Extension
-------------------
Coor #1 - Min =    109.850 - Max =    143.010 - Ext = 33.16
Coor #2 - Min =    483.660 - Max =    513.040 - Ext = 29.38

Variables
---------
Column = 0 - Name = rank - Locator = NA
Column = 1 - Name = X - Locator = x1
Column = 2 - Name = Y - Locator = x2
Column = 3 - Name = Zn - Locator = z1
Column = 4 - Name = Pb - Locator = p1
 ----

Accessing to the variable names

[source, ipython3]
----
print("List of all variable names =",mydb.getAllNames())
----


----
List of all variable names = ('rank', 'X', 'Y', 'Zn', 'Pb')
----

Extracting the vector containing the Zn variable in order to perform a
selection

[source, ipython3]
----
tabZn = mydb.getColumn('Zn')
selZn = (np.asarray(tabZn) < 20).astype(float)
mydb.addSelection(tuple(selZn),'sel')
mydb.setLocator('Pb',gl.ELoc.Z)
if verbose:
    mydb.display()
----


----

Data Base Characteristics
=========================

Data Base Summary
-----------------
File is organized as a set of isolated points
Space dimension              = 2
Number of Columns            = 6
Maximum Number of UIDs       = 6
Total number of samples      = 102
Number of active samples     = 99

Variables
---------
Column = 0 - Name = rank - Locator = NA
Column = 1 - Name = X - Locator = x1
Column = 2 - Name = Y - Locator = x2
Column = 3 - Name = Zn - Locator = NA
Column = 4 - Name = Pb - Locator = z1
Column = 5 - Name = sel - Locator = sel
 ----

Display my Data (with samples represented by color and size)

[source, ipython3]
----
if graphics:
    ax = gp.point(mydb,color_name="Pb",title="Data Set")
----


----
![png](/home/fors/Projets/gstlearn/gstlearn/build/tests/ipynb/Release/output/Tutorial_2D_14_0.png)
----

[[variograms]]
== Variograms

We first define the geometry of the variogram calculations

[source, ipython3]
----
myVarioParamOmni = gl.VarioParam()
mydir = gl.DirParam(2,10,1.)
myVarioParamOmni.addDir(mydir)
----

We use the variogram definition in order to calculate the variogram
cloud.

[source, ipython3]
----
dbcloud = gl.db_variogram_cloud(mydb, myVarioParamOmni)
----

We recall that the Variogram cloud is calculated by filling an
underlying grid where each cell is painted according to the number of
pairs at the given distance and given variability. Representing the
variogram cloud

[source, ipython3]
----
if graphics:
    gp.grid(dbcloud,"Cloud*",title="Variogram Cloud")
----


----
![png](/home/fors/Projets/gstlearn/gstlearn/build/tests/ipynb/Release/output/Tutorial_2D_20_0.png)
----

Calculating the experimental omni-directional variogram

[source, ipython3]
----
myVarioOmni = gl.Vario(myVarioParamOmni,mydb)
err = myVarioOmni.compute(gl.ECalcVario.VARIOGRAM)
if verbose:
    myVarioOmni.display()
----


----

Variogram characteristics
=========================
Number of variable(s)       = 1
Number of direction(s)      = 1
Space dimension             = 2
Variance-Covariance Matrix     2.881

Direction #1
------------
Number of lags              = 10
Direction coefficients      =      1.000     0.000
Direction angles (degrees)  =      0.000     0.000
Tolerance on direction      =     90.000 (degrees)
Calculation lag             =      1.000
Tolerance on distance       =     50.000 (Percent of the lag value)

For variable 1
      Rank    Npairs  Distance     Value
         0     3.000     0.389     0.462
         1   123.000     1.081     1.495
         2   183.000     2.038     1.620
         3   205.000     3.006     2.526
         4   231.000     4.013     2.240
         5   229.000     5.036     2.524
         6   198.000     5.962     2.396
         7   187.000     7.000     2.708
         8   204.000     7.996     2.772
         9   184.000     8.990     2.868
 ----

The variogram is represented graphically for a quick check

[source, ipython3]
----
if graphics:
    axs = gp.varmod(myVarioOmni,title="Omni-directional Variogram for Pb")
----


----
![png](/home/fors/Projets/gstlearn/gstlearn/build/tests/ipynb/Release/output/Tutorial_2D_24_0.png)
----

Calculate a variogram in several directions

[source, ipython3]
----
myvarioParam = gl.VarioParam()
mydirs = gl.DirParam.createMultiple(2, 4, 10, 1.)
myvarioParam.addMultiDirs(mydirs)
myvario = gl.Vario(myvarioParam,mydb)
myvario.compute(gl.ECalcVario.VARIOGRAM)
if verbose:
    myvario.display()
----


----

Variogram characteristics
=========================
Number of variable(s)       = 1
Number of direction(s)      = 4
Space dimension             = 2
Variance-Covariance Matrix     2.881

Direction #1
------------
Number of lags              = 10
Direction coefficients      =      1.000     0.000
Direction angles (degrees)  =      0.000     0.000
Tolerance on direction      =     22.500 (degrees)
Calculation lag             =      1.000
Tolerance on distance       =     50.000 (Percent of the lag value)

For variable 1
      Rank    Npairs  Distance     Value
         0     1.000     0.410     0.180
         1    29.000     1.094     1.634
         2    47.000     2.079     1.415
         3    53.000     3.003     2.824
         4    63.000     3.999     2.348
         5    66.000     5.035     2.319
         6    60.000     5.978     3.115
         7    52.000     7.045     2.746
         8    52.000     8.020     3.927
         9    37.000     8.980     2.554

Direction #2
------------
Number of lags              = 10
Direction coefficients      =      0.707     0.707
Direction angles (degrees)  =     45.000     0.000
Tolerance on direction      =     22.500 (degrees)
Calculation lag             =      1.000
Tolerance on distance       =     50.000 (Percent of the lag value)

For variable 1
      Rank    Npairs  Distance     Value
         0     1.000     0.344     0.080
         1    31.000     1.051     1.113
         2    50.000     1.960     1.890
         3    62.000     2.999     2.443
         4    58.000     4.014     2.701
         5    51.000     5.016     2.702
         6    36.000     5.999     1.833
         7    37.000     7.015     2.130
         8    50.000     7.997     2.060
         9    53.000     8.995     2.381

Direction #3
------------
Number of lags              = 10
Direction coefficients      =      0.000     1.000
Direction angles (degrees)  =     90.000     0.000
Tolerance on direction      =     22.500 (degrees)
Calculation lag             =      1.000
Tolerance on distance       =     50.000 (Percent of the lag value)

For variable 1
      Rank    Npairs  Distance     Value
         1    32.000     1.149     1.631
         2    39.000     2.080     1.670
         3    39.000     2.979     2.511
         4    48.000     4.012     2.120
         5    51.000     5.029     3.055
         6    47.000     5.939     2.856
         7    49.000     6.965     2.386
         8    42.000     7.952     2.708
         9    41.000     9.018     2.320

Direction #4
------------
Number of lags              = 10
Direction coefficients      =     -0.707     0.707
Direction angles (degrees)  =    135.000     0.000
Tolerance on direction      =     22.500 (degrees)
Calculation lag             =      1.000
Tolerance on distance       =     50.000 (Percent of the lag value)

For variable 1
      Rank    Npairs  Distance     Value
         0     1.000     0.411     1.125
         1    31.000     1.028     1.606
         2    47.000     2.044     1.496
         3    51.000     3.040     2.330
         4    62.000     4.028     1.791
         5    61.000     5.058     2.155
         6    55.000     5.939     1.587
         7    49.000     6.975     3.425
         8    60.000     8.004     2.408
         9    53.000     8.972     3.996
 ----

[source, ipython3]
----
if graphics:
    axs = gp.varmod(myvario,title="Multi-Directional Variogram of Pb")
----


----
![png](/home/fors/Projets/gstlearn/gstlearn/build/tests/ipynb/Release/output/Tutorial_2D_27_0.png)
----

Calculating the Variogram Map

[source, ipython3]
----
myvmap = gl.db_vmap_compute(mydb,gl.ECalcVario.VARIOGRAM,[20,20])
if verbose:
    myvmap.display()
----


----

Data Base Grid Characteristics
==============================

Data Base Summary
-----------------
File is organized as a regular grid
Space dimension              = 2
Number of Columns            = 5
Maximum Number of UIDs       = 5
Total number of samples      = 1681

Grid characteristics:
---------------------
Origin :    -33.160   -29.380
Mesh   :      1.658     1.469
Number :         41        41

Variables
---------
Column = 0 - Name = rank - Locator = NA
Column = 1 - Name = x1 - Locator = x1
Column = 2 - Name = x2 - Locator = x2
Column = 3 - Name = VMAP.Pb.Var - Locator = z1
Column = 4 - Name = VMAP.Pb.Nb - Locator = NA
 ----

[source, ipython3]
----
if graphics:
    gp.grid(myvmap,"*Var",title="Variogram Map")
----


----
![png](/home/fors/Projets/gstlearn/gstlearn/build/tests/ipynb/Release/output/Tutorial_2D_30_0.png)
----

[[model]]
== Model

Fitting a Model. We call the Automatic Fitting procedure providing the
list of covariance functions to be tested.

[source, ipython3]
----
mymodel = gl.Model.createFromDb(mydb)
err = mymodel.fit(myvario,[gl.ECov.EXPONENTIAL,gl.ECov.SPHERICAL])
----

Visualizing the resulting model, overlaid on the experimental variogram

[source, ipython3]
----
if graphics:
    axs = gp.varmod(myvario,mymodel,title="Model for Pb")
----


----
![png](/home/fors/Projets/gstlearn/gstlearn/build/tests/ipynb/Release/output/Tutorial_2D_34_0.png)
----

A IRF-0 model is created from this Covariance, adding the Universality
Drift term

[[model-with-equality-constraints]]
=== Model with equality constraints

We can impose some constraints on the parameters during the fit. For
instance here, we impose an equality constraint on the range (range =
1).

[source, ipython3]
----
myModelConstrained = gl.Model.createFromDb(mydb)
constr = gl.Constraints()
paramid = gl.CovParamId(0,0,gl.EConsElem.RANGE,0,0)
constr.addItem(gl.ConsItem(paramid,gl.EConsType.EQUAL,1.))
opt = gl.Option_AutoFit()
err = myModelConstrained.fit(myVarioOmni,[gl.ECov.SPHERICAL],False,opt,constr)
myModelConstrained
----


----
Model characteristics
=====================
Space dimension              = 2
Number of variable(s)        = 1
Number of basic structure(s) = 1
Number of drift function(s)  = 0
Number of drift equation(s)  = 0

Covariance Part
---------------
Spherical
- Sill         =      2.101
- Range        =      1.000
Total Sill     =      2.101----

We can impose inequality constraints by using *EConsType.LOWER* or
*EConsType.UPPER*.

[[adding-a-drift]]
== Adding a drift :

[source, ipython3]
----
mymodel.addDrift(gl.Drift1(mymodel.getContext()))
if verbose:
    mymodel.display()
----


----

Model characteristics
=====================
Space dimension              = 2
Number of variable(s)        = 1
Number of basic structure(s) = 2
Number of drift function(s)  = 1
Number of drift equation(s)  = 1

Covariance Part
---------------
Exponential
- Sill         =      1.035
- Ranges       =      1.786     0.366
- Theo. Ranges =      0.596     0.122
- Angles       =    405.023     0.000
- Rotation Matrix
               [,  0]    [,  1]
     [  0,]     0.707    -0.707
     [  1,]     0.707     0.707
Spherical
- Sill         =      1.621
- Ranges       =      7.051     5.132
- Angles       =   1576.897     0.000
- Rotation Matrix
               [,  0]    [,  1]
     [  0,]    -0.730    -0.683
     [  1,]     0.683    -0.730
Total Sill     =      2.656

Drift Part
----------
Universality Condition
 ----

[[defining-the-neighborhood]]
== Defining the Neighborhood

We initiate a Neigborhood (Moving with a small number of samples for
Demonstration)

[source, ipython3]
----
myneigh = gl.NeighMoving.create(2,False,6,10)
if verbose:
    myneigh.display()
----


----

Moving Neighborhood
===================
Space dimension = 2
Minimum number of samples           = 1
Maximum number of samples           = 6
Maximum horizontal distance         = 10
 ----

[[checking-the-moving-neighborhood]]
== Checking the Moving Neighborhood

We must first create a Grid which covers the area of interest

[source, ipython3]
----
mygrid = gl.DbGrid()
mygrid.resetCoveringDb(mydb,[],[0.5,0.5],[],[2,2])
if verbose:
    mygrid.display()
----


----

Data Base Grid Characteristics
==============================

Data Base Summary
-----------------
File is organized as a regular grid
Space dimension              = 2
Number of Columns            = 2
Maximum Number of UIDs       = 2
Total number of samples      = 5760

Grid characteristics:
---------------------
Origin :    107.850   481.660
Mesh   :      0.500     0.500
Number :         80        72

Variables
---------
Column = 0 - Name = x1 - Locator = x1
Column = 1 - Name = x2 - Locator = x2
 ----

We can now test the neighborhood characteristics for each node of the
previously defined grid.

[source, ipython3]
----
err = gl.test_neigh(mydb,mygrid,mymodel,myneigh)
if verbose:
    mygrid.display()
----


----

Data Base Grid Characteristics
==============================

Data Base Summary
-----------------
File is organized as a regular grid
Space dimension              = 2
Number of Columns            = 7
Maximum Number of UIDs       = 7
Total number of samples      = 5760

Grid characteristics:
---------------------
Origin :    107.850   481.660
Mesh   :      0.500     0.500
Number :         80        72

Variables
---------
Column = 0 - Name = x1 - Locator = x1
Column = 1 - Name = x2 - Locator = x2
Column = 2 - Name = Neigh.Number - Locator = z1
Column = 3 - Name = Neigh.MaxDist - Locator = z2
Column = 4 - Name = Neigh.MinDist - Locator = z3
Column = 5 - Name = Neigh.NbNESect - Locator = z4
Column = 6 - Name = Neigh.NbCESect - Locator = z5
 ----

We can visualize some of the newly created variables, such as:

* the number of points per neighborhood

[source, ipython3]
----
if graphics:
    gp.grid(mygrid,"Neigh*Number",title="Number of Samples per Neighborhood")
----


----
![png](/home/fors/Projets/gstlearn/gstlearn/build/tests/ipynb/Release/output/Tutorial_2D_48_0.png)
----

* the one giving the maximum distance per neighborhood

[source, ipython3]
----
if graphics:
    gp.grid(mygrid,"Neigh*MaxDist",title="Maximum Distance per Neighborhood")
----


----
![png](/home/fors/Projets/gstlearn/gstlearn/build/tests/ipynb/Release/output/Tutorial_2D_50_0.png)
----

[[cross-validation]]
== Cross-validation

We can now process the cross-validation step

[source, ipython3]
----
err = gl.xvalid(mydb,mymodel,myneigh)
if verbose:
    mydb.display()
----


----

Data Base Characteristics
=========================

Data Base Summary
-----------------
File is organized as a set of isolated points
Space dimension              = 2
Number of Columns            = 8
Maximum Number of UIDs       = 8
Total number of samples      = 102
Number of active samples     = 99

Variables
---------
Column = 0 - Name = rank - Locator = NA
Column = 1 - Name = X - Locator = x1
Column = 2 - Name = Y - Locator = x2
Column = 3 - Name = Zn - Locator = NA
Column = 4 - Name = Pb - Locator = NA
Column = 5 - Name = sel - Locator = sel
Column = 6 - Name = Xvalid.Pb.esterr - Locator = z1
Column = 7 - Name = Xvalid.Pb.stderr - Locator = NA
 ----

[source, ipython3]
----
if graphics:
    ax = gp.hist(mydb,"Xvalid.Pb.stderr")
----


----
![png](/home/fors/Projets/gstlearn/gstlearn/build/tests/ipynb/Release/output/Tutorial_2D_53_0.png)
----

[[estimation-by-kriging]]
== Estimation by Kriging

We now perform the Estimation by Ordinary Kriging. The Neighborhood is
changed into a Unique Neighborhood.

[source, ipython3]
----
mydb.setLocator("Pb",gl.ELoc.Z)
myneigh = gl.NeighUnique.create(2)
err = gl.kriging(mydb,mygrid,mymodel,myneigh)
if verbose:
    mygrid.display()
----


----

Data Base Grid Characteristics
==============================

Data Base Summary
-----------------
File is organized as a regular grid
Space dimension              = 2
Number of Columns            = 9
Maximum Number of UIDs       = 9
Total number of samples      = 5760

Grid characteristics:
---------------------
Origin :    107.850   481.660
Mesh   :      0.500     0.500
Number :         80        72

Variables
---------
Column = 0 - Name = x1 - Locator = x1
Column = 1 - Name = x2 - Locator = x2
Column = 2 - Name = Neigh.Number - Locator = NA
Column = 3 - Name = Neigh.MaxDist - Locator = NA
Column = 4 - Name = Neigh.MinDist - Locator = NA
Column = 5 - Name = Neigh.NbNESect - Locator = NA
Column = 6 - Name = Neigh.NbCESect - Locator = NA
Column = 7 - Name = Kriging.Pb.estim - Locator = z1
Column = 8 - Name = Kriging.Pb.stdev - Locator = NA
 ----

Visualizing the results

[source, ipython3]
----
if graphics:
    ax = gp.grid(mygrid,"Kriging.Pb.estim")
    ax = gp.point(mydb,"Pb",title="Estimate of Pb",ax=ax)
----


----
![png](/home/fors/Projets/gstlearn/gstlearn/build/tests/ipynb/Release/output/Tutorial_2D_57_0.png)
----

[source, ipython3]
----
if graphics:
    ax = gp.grid(mygrid,"Kriging.Pb.stdev")
    ax = gp.point(mydb,"Pb",title="St. Deviation of Pb",ax=ax)
----


----
![png](/home/fors/Projets/gstlearn/gstlearn/build/tests/ipynb/Release/output/Tutorial_2D_58_0.png)
----

[[simulations]]
== Simulations

We must first transform the Data into Gaussian

[source, ipython3]
----
myanamPb = gl.AnamHermite(30)
myanamPb.fit(mydb)
if verbose:
    myanamPb.display()
----


----

Hermitian Anamorphosis
----------------------
Minimum absolute value for Y  = -2.7
Maximum absolute value for Y  = 2.6
Minimum absolute value for Z  = 3.0029
Maximum absolute value for Z  = 12.9777
Minimum practical value for Y = -2.7
Maximum practical value for Y = 2.6
Minimum practical value for Z = 3.0029
Maximum practical value for Z = 12.9777
Mean                          = 5.65758
Variance                      = 2.86296
Number of Hermite polynomials = 30
Normalized coefficients for Hermite polynomials
               [,  0]    [,  1]    [,  2]    [,  3]    [,  4]    [,  5]    [,  6]
     [  0,]     5.658    -1.625     0.440    -0.069    -0.017     0.082    -0.061
     [  7,]     0.001     0.036    -0.044     0.004     0.047    -0.030    -0.029
     [ 14,]     0.037     0.007    -0.031     0.010     0.018    -0.019    -0.003
     [ 21,]     0.019    -0.010    -0.014     0.019     0.006    -0.023     0.004
     [ 28,]     0.022    -0.013
 ----

We can produce the Gaussian Anamorphosis graphically within its
definition domain.

[source, ipython3]
----
if graphics:
    res = myanamPb.sample()
    ax = gp.XY(res.getY(),res.getZ(),xlim=res.getAylim(),ylim=res.getAzlim(),title="Gaussian Anamorphosis for Pb")
----


----
![png](/home/fors/Projets/gstlearn/gstlearn/build/tests/ipynb/Release/output/Tutorial_2D_62_0.png)
----

The next step consists in translating the target variable ('Pb') into
its Gaussian transform

[source, ipython3]
----
mydb.setLocator("Pb",gl.ELoc.Z)
err = myanamPb.RawToGaussian(mydb)
if verbose:
    mydb.display()
----


----

Data Base Characteristics
=========================

Data Base Summary
-----------------
File is organized as a set of isolated points
Space dimension              = 2
Number of Columns            = 9
Maximum Number of UIDs       = 9
Total number of samples      = 102
Number of active samples     = 99

Variables
---------
Column = 0 - Name = rank - Locator = NA
Column = 1 - Name = X - Locator = x1
Column = 2 - Name = Y - Locator = x2
Column = 3 - Name = Zn - Locator = NA
Column = 4 - Name = Pb - Locator = NA
Column = 5 - Name = sel - Locator = sel
Column = 6 - Name = Xvalid.Pb.esterr - Locator = NA
Column = 7 - Name = Xvalid.Pb.stderr - Locator = NA
Column = 8 - Name = Y.Pb - Locator = z1
 ----

We quickly calculate experimental (omni-directional) variograms using
the already defined directions

[source, ipython3]
----
myvarioParam = gl.VarioParam()
mydir = gl.DirParam(2,10,1.)
myvarioParam.addDir(mydir)
myVario = gl.Vario(myvarioParam,mydb)
err = myvario.compute(gl.ECalcVario.VARIOGRAM)
----

We fit the model by automatic fit (with the constraints that the total
sill be equal to 1).

[source, ipython3]
----
mymodelG = gl.Model.createFromDb(mydb)
err = mymodelG.fit(myvario,[gl.ECov.EXPONENTIAL])
if graphics:
    ax = gp.varmod(myvario,mymodelG,title="Model for Gaussian Pb")
----


----
![png](/home/fors/Projets/gstlearn/gstlearn/build/tests/ipynb/Release/output/Tutorial_2D_68_0.png)
----

We perform a set of 10 conditional simulations using the Turning Bands
Method.

[source, ipython3]
----
err = gl.simtub(mydb,mygrid,mymodel,myneigh,10)
if verbose:
    mygrid.display()
----


----

Data Base Grid Characteristics
==============================

Data Base Summary
-----------------
File is organized as a regular grid
Space dimension              = 2
Number of Columns            = 19
Maximum Number of UIDs       = 19
Total number of samples      = 5760

Grid characteristics:
---------------------
Origin :    107.850   481.660
Mesh   :      0.500     0.500
Number :         80        72

Variables
---------
Column = 0 - Name = x1 - Locator = x1
Column = 1 - Name = x2 - Locator = x2
Column = 2 - Name = Neigh.Number - Locator = NA
Column = 3 - Name = Neigh.MaxDist - Locator = NA
Column = 4 - Name = Neigh.MinDist - Locator = NA
Column = 5 - Name = Neigh.NbNESect - Locator = NA
Column = 6 - Name = Neigh.NbCESect - Locator = NA
Column = 7 - Name = Kriging.Pb.estim - Locator = NA
Column = 8 - Name = Kriging.Pb.stdev - Locator = NA
Column = 9 - Name = Simu.Y.Pb.1 - Locator = z1
Column = 10 - Name = Simu.Y.Pb.2 - Locator = z2
Column = 11 - Name = Simu.Y.Pb.3 - Locator = z3
Column = 12 - Name = Simu.Y.Pb.4 - Locator = z4
Column = 13 - Name = Simu.Y.Pb.5 - Locator = z5
Column = 14 - Name = Simu.Y.Pb.6 - Locator = z6
Column = 15 - Name = Simu.Y.Pb.7 - Locator = z7
Column = 16 - Name = Simu.Y.Pb.8 - Locator = z8
Column = 17 - Name = Simu.Y.Pb.9 - Locator = z9
Column = 18 - Name = Simu.Y.Pb.10 - Locator = z10
 ----

Some statistics on the Conditional simulations in Gaussian scale

[source, ipython3]
----
if verbose:
    err = mygrid.statistics(["Simu.Y.*"],["mini","maxi","mean","stdv"],True,True,True)
----


----
              Minimum   Maximum      Mean  St. Dev.
Simu.Y.Pb.1      -5.638     6.293     0.126     1.578
Simu.Y.Pb.2      -5.437     7.185     0.456     1.603
Simu.Y.Pb.3      -7.024     6.249    -0.202     1.651
Simu.Y.Pb.4      -5.573     6.267     0.668     1.576
Simu.Y.Pb.5      -5.216     6.403     0.615     1.622
Simu.Y.Pb.6      -5.677     6.429     0.223     1.659
Simu.Y.Pb.7      -4.521     6.670     0.812     1.648
Simu.Y.Pb.8      -4.898     6.028     0.567     1.645
Simu.Y.Pb.9      -4.897     6.487     0.204     1.549
Simu.Y.Pb.10     -5.901     6.146    -0.109     1.571
 ----

We visualize a conditional simulation in Gaussian scale

[source, ipython3]
----
if graphics:
    ax = gp.grid(mygrid,"Simu.Y.Pb.1")
    ax = gp.point(mydb,"Pb",title="One Simulation of Pb in Gaussian Scale",ax=ax)
----


----
![png](/home/fors/Projets/gstlearn/gstlearn/build/tests/ipynb/Release/output/Tutorial_2D_74_0.png)
----

We turn the Gaussian conditional simulations into Raw scale (using the
Anamorphosis back transform) and get rid of the Gaussian conditional
simulations.

[source, ipython3]
----
myanamPb.GaussianToRaw(mygrid,"Simu.Y.*")
mygrid.deleteColumn("Simu.Y.*")
if verbose:
    mygrid.display()
----


----

Data Base Grid Characteristics
==============================

Data Base Summary
-----------------
File is organized as a regular grid
Space dimension              = 2
Number of Columns            = 19
Maximum Number of UIDs       = 29
Total number of samples      = 5760

Grid characteristics:
---------------------
Origin :    107.850   481.660
Mesh   :      0.500     0.500
Number :         80        72

Variables
---------
Column = 0 - Name = x1 - Locator = x1
Column = 1 - Name = x2 - Locator = x2
Column = 2 - Name = Neigh.Number - Locator = NA
Column = 3 - Name = Neigh.MaxDist - Locator = NA
Column = 4 - Name = Neigh.MinDist - Locator = NA
Column = 5 - Name = Neigh.NbNESect - Locator = NA
Column = 6 - Name = Neigh.NbCESect - Locator = NA
Column = 7 - Name = Kriging.Pb.estim - Locator = NA
Column = 8 - Name = Kriging.Pb.stdev - Locator = NA
Column = 9 - Name = Z.Simu.Y.Pb.1 - Locator = z1
Column = 10 - Name = Z.Simu.Y.Pb.2 - Locator = z2
Column = 11 - Name = Z.Simu.Y.Pb.3 - Locator = z3
Column = 12 - Name = Z.Simu.Y.Pb.4 - Locator = z4
Column = 13 - Name = Z.Simu.Y.Pb.5 - Locator = z5
Column = 14 - Name = Z.Simu.Y.Pb.6 - Locator = z6
Column = 15 - Name = Z.Simu.Y.Pb.7 - Locator = z7
Column = 16 - Name = Z.Simu.Y.Pb.8 - Locator = z8
Column = 17 - Name = Z.Simu.Y.Pb.9 - Locator = z9
Column = 18 - Name = Z.Simu.Y.Pb.10 - Locator = z10
 ----

We calculate some statistics on the Conditional Simulations in Raw
scale.

[source, ipython3]
----
if verbose:
    err = mygrid.statistics(["Z.Simu.*"],["mini","maxi","mean","stdv"],True,True,True)
----


----
              Minimum   Maximum      Mean  St. Dev.
Z.Simu.Y.Pb.1       3.003    12.978     6.250     2.750
Z.Simu.Y.Pb.2       3.003    12.978     6.838     2.985
Z.Simu.Y.Pb.3       3.003    12.978     5.808     2.626
Z.Simu.Y.Pb.4       3.003    12.978     7.217     3.063
Z.Simu.Y.Pb.5       3.003    12.978     7.123     3.069
Z.Simu.Y.Pb.6       3.003    12.978     6.475     2.908
Z.Simu.Y.Pb.7       3.003    12.978     7.492     3.176
Z.Simu.Y.Pb.8       3.003    12.978     7.046     3.077
Z.Simu.Y.Pb.9       3.003    12.978     6.379     2.806
Z.Simu.Y.Pb.10      3.003    12.978     5.894     2.637
 ----

We visualize a Conditional Simulation in Raw Scale

[source, ipython3]
----
if graphics:
    ax = gp.grid(mygrid,"Z.Simu.Y.Pb.1")
    ax = gp.point(mydb,"Pb",title="One simulation of Pb in Raw Scale", ax=ax)
----


----
![png](/home/fors/Projets/gstlearn/gstlearn/build/tests/ipynb/Release/output/Tutorial_2D_80_0.png)
----

Let us now average the conditional simulations in order to have a
comparison with the estimation by kriging.

[source, ipython3]
----
err = mygrid.statistics(["Z.Simu.*"],["Mean"],True,False,False)
if verbose:
    mygrid.display()
----


----

Data Base Grid Characteristics
==============================

Data Base Summary
-----------------
File is organized as a regular grid
Space dimension              = 2
Number of Columns            = 20
Maximum Number of UIDs       = 30
Total number of samples      = 5760

Grid characteristics:
---------------------
Origin :    107.850   481.660
Mesh   :      0.500     0.500
Number :         80        72

Variables
---------
Column = 0 - Name = x1 - Locator = x1
Column = 1 - Name = x2 - Locator = x2
Column = 2 - Name = Neigh.Number - Locator = NA
Column = 3 - Name = Neigh.MaxDist - Locator = NA
Column = 4 - Name = Neigh.MinDist - Locator = NA
Column = 5 - Name = Neigh.NbNESect - Locator = NA
Column = 6 - Name = Neigh.NbCESect - Locator = NA
Column = 7 - Name = Kriging.Pb.estim - Locator = NA
Column = 8 - Name = Kriging.Pb.stdev - Locator = NA
Column = 9 - Name = Z.Simu.Y.Pb.1 - Locator = NA
Column = 10 - Name = Z.Simu.Y.Pb.2 - Locator = NA
Column = 11 - Name = Z.Simu.Y.Pb.3 - Locator = NA
Column = 12 - Name = Z.Simu.Y.Pb.4 - Locator = NA
Column = 13 - Name = Z.Simu.Y.Pb.5 - Locator = NA
Column = 14 - Name = Z.Simu.Y.Pb.6 - Locator = NA
Column = 15 - Name = Z.Simu.Y.Pb.7 - Locator = NA
Column = 16 - Name = Z.Simu.Y.Pb.8 - Locator = NA
Column = 17 - Name = Z.Simu.Y.Pb.9 - Locator = NA
Column = 18 - Name = Z.Simu.Y.Pb.10 - Locator = NA
Column = 19 - Name = Stats.Mean - Locator = z1
 ----

Displaying the average of the Conditional Simulations

[source, ipython3]
----
if graphics:
    ax = gp.grid(mygrid,"Stats*Mean")
    ax = gp.point(mydb,"Pb",title="Mean of Pb simulations",ax=ax)
----


----
![png](/home/fors/Projets/gstlearn/gstlearn/build/tests/ipynb/Release/output/Tutorial_2D_84_0.png)
----

[[multivariate-case]]
== Multivariate case

The Gaussian transform of the Pb variable has already been calculated.
It suffices to perform the Gaussian transform of the Zn variable

[source, ipython3]
----
mydb.setLocator("Zn",gl.ELoc.Z)
myanamZn = gl.AnamHermite(30)
myanamZn.fit(mydb)
if verbose:
    myanamZn.display()
----


----

Hermitian Anamorphosis
----------------------
Minimum absolute value for Y  = -2.5
Maximum absolute value for Y  = 2.6
Minimum absolute value for Z  = 1.1469
Maximum absolute value for Z  = 12.1276
Minimum practical value for Y = -2.5
Maximum practical value for Y = 2.6
Minimum practical value for Z = 1.1469
Maximum practical value for Z = 12.1276
Mean                          = 2.88061
Variance                      = 2.76263
Number of Hermite polynomials = 30
Normalized coefficients for Hermite polynomials
               [,  0]    [,  1]    [,  2]    [,  3]    [,  4]    [,  5]    [,  6]
     [  0,]     2.881    -1.277     0.877    -0.447    -0.095     0.294    -0.121
     [  7,]    -0.087     0.134    -0.029    -0.087     0.069     0.034    -0.065
     [ 14,]     0.005     0.044    -0.026    -0.020     0.034     0.001    -0.033
     [ 21,]     0.010     0.027    -0.016    -0.019     0.016     0.012    -0.014
     [ 28,]    -0.005     0.011
 ----

[source, ipython3]
----
if graphics:
    res = myanamZn.sample()
    ax = gp.XY(res.getY(),res.getZ(),xlim=res.getAylim(),ylim=res.getAzlim(),title="Gaussian Anamorphosis for Zn")
----


----
![png](/home/fors/Projets/gstlearn/gstlearn/build/tests/ipynb/Release/output/Tutorial_2D_87_0.png)
----

We convert the raw data into its Gaussian equivalent

[source, ipython3]
----
mydb.setLocator("Zn",gl.ELoc.Z)
err = myanamZn.RawToGaussian(mydb)
if verbose:
    mydb.display()
----


----

Data Base Characteristics
=========================

Data Base Summary
-----------------
File is organized as a set of isolated points
Space dimension              = 2
Number of Columns            = 10
Maximum Number of UIDs       = 20
Total number of samples      = 102
Number of active samples     = 99

Variables
---------
Column = 0 - Name = rank - Locator = NA
Column = 1 - Name = X - Locator = x1
Column = 2 - Name = Y - Locator = x2
Column = 3 - Name = Zn - Locator = NA
Column = 4 - Name = Pb - Locator = NA
Column = 5 - Name = sel - Locator = sel
Column = 6 - Name = Xvalid.Pb.esterr - Locator = NA
Column = 7 - Name = Xvalid.Pb.stderr - Locator = NA
Column = 8 - Name = Y.Pb - Locator = NA
Column = 9 - Name = Y.Zn - Locator = z1
 ----

We now perform the multivariate variogram caculation

[source, ipython3]
----
mydb.setLocators(["Y.Pb","Y.Zn"],gl.ELoc.Z)
myvario = gl.Vario(myvarioParam,mydb)
err = myvario.compute(gl.ECalcVario.VARIOGRAM)
mymodelM = gl.Model.createFromDb(mydb)
err = mymodelM.fit(myvario,[gl.ECov.EXPONENTIAL])
if graphics:
    ax = gp.varmod(myvario,mymodelM,title="Multivariate Model",figsize=[5,5])
----


----
![png](/home/fors/Projets/gstlearn/gstlearn/build/tests/ipynb/Release/output/Tutorial_2D_91_0.png)
----

We perform 10 bivariate conditional simulations (deleting the previous
monovariate simulation outcomes first for better legibility)

[source, ipython3]
----
mygrid.deleteColumn("Z.Simu*")
err = gl.simtub(mydb,mygrid,mymodelM,myneigh,10)
if verbose:
    mygrid.display()
----


----

Data Base Grid Characteristics
==============================

Data Base Summary
-----------------
File is organized as a regular grid
Space dimension              = 2
Number of Columns            = 30
Maximum Number of UIDs       = 50
Total number of samples      = 5760

Grid characteristics:
---------------------
Origin :    107.850   481.660
Mesh   :      0.500     0.500
Number :         80        72

Variables
---------
Column = 0 - Name = x1 - Locator = x1
Column = 1 - Name = x2 - Locator = x2
Column = 2 - Name = Neigh.Number - Locator = NA
Column = 3 - Name = Neigh.MaxDist - Locator = NA
Column = 4 - Name = Neigh.MinDist - Locator = NA
Column = 5 - Name = Neigh.NbNESect - Locator = NA
Column = 6 - Name = Neigh.NbCESect - Locator = NA
Column = 7 - Name = Kriging.Pb.estim - Locator = NA
Column = 8 - Name = Kriging.Pb.stdev - Locator = NA
Column = 9 - Name = Stats.Mean - Locator = NA
Column = 10 - Name = Simu.Y.Pb.1 - Locator = z1
Column = 11 - Name = Simu.Y.Pb.2 - Locator = z2
Column = 12 - Name = Simu.Y.Pb.3 - Locator = z3
Column = 13 - Name = Simu.Y.Pb.4 - Locator = z4
Column = 14 - Name = Simu.Y.Pb.5 - Locator = z5
Column = 15 - Name = Simu.Y.Pb.6 - Locator = z6
Column = 16 - Name = Simu.Y.Pb.7 - Locator = z7
Column = 17 - Name = Simu.Y.Pb.8 - Locator = z8
Column = 18 - Name = Simu.Y.Pb.9 - Locator = z9
Column = 19 - Name = Simu.Y.Pb.10 - Locator = z10
Column = 20 - Name = Simu.Y.Zn.1 - Locator = z11
Column = 21 - Name = Simu.Y.Zn.2 - Locator = z12
Column = 22 - Name = Simu.Y.Zn.3 - Locator = z13
Column = 23 - Name = Simu.Y.Zn.4 - Locator = z14
Column = 24 - Name = Simu.Y.Zn.5 - Locator = z15
Column = 25 - Name = Simu.Y.Zn.6 - Locator = z16
Column = 26 - Name = Simu.Y.Zn.7 - Locator = z17
Column = 27 - Name = Simu.Y.Zn.8 - Locator = z18
Column = 28 - Name = Simu.Y.Zn.9 - Locator = z19
Column = 29 - Name = Simu.Y.Zn.10 - Locator = z20
 ----

We back-transform each set of simulation outcomes using its own Gaussian
Anamorphosis function. Finally we delete the Gaussian variables and ask
for the statistics on the simulated variables in the Raw Scale.

[source, ipython3]
----
err = myanamZn.GaussianToRaw(mygrid,"Simu.Y.Zn*")
err = myanamPb.GaussianToRaw(mygrid,"Simu.Y.Pb*")
mygrid.deleteColumn("Simu.Y*")
if verbose:
    err = mygrid.statistics(["Z.Simu.*"],["mini","maxi","mean","stdv"],True,True,True)
----


----
              Minimum   Maximum      Mean  St. Dev.
Z.Simu.Y.Zn.1       1.147    12.128     2.831     1.558
Z.Simu.Y.Zn.2       1.147    12.128     2.699     1.421
Z.Simu.Y.Zn.3       1.147    12.128     2.931     1.724
Z.Simu.Y.Zn.4       1.147    12.128     2.799     1.531
Z.Simu.Y.Zn.5       1.147    12.128     2.885     1.585
Z.Simu.Y.Zn.6       1.147    12.128     2.967     1.652
Z.Simu.Y.Zn.7       1.147    12.128     2.828     1.599
Z.Simu.Y.Zn.8       1.147    12.128     2.867     1.582
Z.Simu.Y.Zn.9       1.147    12.128     2.811     1.558
Z.Simu.Y.Zn.10      1.147    12.128     2.872     1.602
Z.Simu.Y.Pb.1       3.003    12.978     5.790     1.794
Z.Simu.Y.Pb.2       3.003    12.978     5.748     1.819
Z.Simu.Y.Pb.3       3.003    12.978     5.437     1.763
Z.Simu.Y.Pb.4       3.003    12.978     5.808     1.839
Z.Simu.Y.Pb.5       3.003    12.978     5.739     1.831
Z.Simu.Y.Pb.6       3.003    12.978     5.558     1.705
Z.Simu.Y.Pb.7       3.003    12.978     5.634     1.702
Z.Simu.Y.Pb.8       3.003    12.978     5.733     1.784
Z.Simu.Y.Pb.9       3.003    12.978     5.738     1.806
Z.Simu.Y.Pb.10      3.003    12.978     5.633     1.707
 ----

[[categorical-variable]]
== Categorical Variable

We compare the initial variable 'Pb' with a set of disjoint intervals.
The 'Pb' values varying from 3 to 12.7, we consider three classes: -
values below 4 - values between 4 and 6 - values above 6

We first build the indicators for each class

[source, ipython3]
----
limits = gl.Limits([np.nan, 4., 6., np.nan])
if verbose:
    limits.display()
----


----
Bound( 1 ) : ] -Inf ; 4 [
Bound( 2 ) : [ 4 ; 6 [
Bound( 3 ) : [ 6 ;  +Inf [
 ----

We apply the set of limits previously defined in order to transform the
input variable into Indicators of the different classes.

[source, ipython3]
----
err = limits.toIndicator(mydb,"Pb")
if verbose:
    mydb.display()
----


----

Data Base Characteristics
=========================

Data Base Summary
-----------------
File is organized as a set of isolated points
Space dimension              = 2
Number of Columns            = 13
Maximum Number of UIDs       = 43
Total number of samples      = 102
Number of active samples     = 99

Variables
---------
Column = 0 - Name = rank - Locator = NA
Column = 1 - Name = X - Locator = x1
Column = 2 - Name = Y - Locator = x2
Column = 3 - Name = Zn - Locator = NA
Column = 4 - Name = Pb - Locator = NA
Column = 5 - Name = sel - Locator = sel
Column = 6 - Name = Xvalid.Pb.esterr - Locator = NA
Column = 7 - Name = Xvalid.Pb.stderr - Locator = NA
Column = 8 - Name = Y.Pb - Locator = NA
Column = 9 - Name = Y.Zn - Locator = NA
Column = 10 - Name = Indicator.Pb.Class.1 - Locator = z1
Column = 11 - Name = Indicator.Pb.Class.2 - Locator = z2
Column = 12 - Name = Indicator.Pb.Class.3 - Locator = z3
 ----

We calculate the variogram of the Indicators for future use

[source, ipython3]
----
myvarioindParam = gl.VarioParam()
myvarioindParam.addDir(mydir)
myvarioInd = gl.Vario(myvarioindParam,mydb)
err = myvarioInd.compute(gl.ECalcVario.VARIOGRAM)
if verbose:
    myvarioInd.display()
----


----

Variogram characteristics
=========================
Number of variable(s)       = 3
Number of direction(s)      = 1
Space dimension             = 2
Variance-Covariance Matrix
               [,  0]    [,  1]    [,  2]
     [  0,]     0.107    -0.062    -0.044
     [  1,]    -0.062     0.250    -0.187
     [  2,]    -0.044    -0.187     0.231

Direction #1
------------
Number of lags              = 10
Direction coefficients      =      1.000     0.000
Direction angles (degrees)  =      0.000     0.000
Tolerance on direction      =     90.000 (degrees)
Calculation lag             =      1.000
Tolerance on distance       =     50.000 (Percent of the lag value)

For variable 1
      Rank    Npairs  Distance     Value
         0     3.000     0.389     0.000
         1   123.000     1.081     0.081
         2   183.000     2.038     0.126
         3   205.000     3.006     0.156
         4   231.000     4.013     0.132
         5   229.000     5.036     0.159
         6   198.000     5.962     0.152
         7   187.000     7.000     0.107
         8   204.000     7.996     0.096
         9   184.000     8.990     0.068

For variables 2 and 1
      Rank    Npairs  Distance     Value
         0     3.000     0.389     0.000
         1   123.000     1.081    -0.065
         2   183.000     2.038    -0.077
         3   205.000     3.006    -0.085
         4   231.000     4.013    -0.093
         5   229.000     5.036    -0.085
         6   198.000     5.962    -0.061
         7   187.000     7.000    -0.045
         8   204.000     7.996    -0.042
         9   184.000     8.990    -0.038

For variable 2
      Rank    Npairs  Distance     Value
         0     3.000     0.389     0.167
         1   123.000     1.081     0.199
         2   183.000     2.038     0.221
         3   205.000     3.006     0.251
         4   231.000     4.013     0.292
         5   229.000     5.036     0.258
         6   198.000     5.962     0.237
         7   187.000     7.000     0.254
         8   204.000     7.996     0.228
         9   184.000     8.990     0.234

For variables 3 and 1
      Rank    Npairs  Distance     Value
         0     3.000     0.389     0.000
         1   123.000     1.081    -0.016
         2   183.000     2.038    -0.049
         3   205.000     3.006    -0.071
         4   231.000     4.013    -0.039
         5   229.000     5.036    -0.074
         6   198.000     5.962    -0.091
         7   187.000     7.000    -0.061
         8   204.000     7.996    -0.054
         9   184.000     8.990    -0.030

For variables 3 and 2
      Rank    Npairs  Distance     Value
         0     3.000     0.389    -0.167
         1   123.000     1.081    -0.134
         2   183.000     2.038    -0.145
         3   205.000     3.006    -0.166
         4   231.000     4.013    -0.199
         5   229.000     5.036    -0.172
         6   198.000     5.962    -0.177
         7   187.000     7.000    -0.209
         8   204.000     7.996    -0.186
         9   184.000     8.990    -0.196

For variable 3
      Rank    Npairs  Distance     Value
         0     3.000     0.389     0.167
         1   123.000     1.081     0.150
         2   183.000     2.038     0.194
         3   205.000     3.006     0.237
         4   231.000     4.013     0.238
         5   229.000     5.036     0.247
         6   198.000     5.962     0.268
         7   187.000     7.000     0.270
         8   204.000     7.996     0.240
         9   184.000     8.990     0.226
 ----

[source, ipython3]
----
ax = gp.varmod(myvarioInd)
----


----
![png](/home/fors/Projets/gstlearn/gstlearn/build/tests/ipynb/Release/output/Tutorial_2D_102_0.png)
----

Then we build a categorical variable which gives the index of the class
to which each sample belongs

[source, ipython3]
----
err = limits.toCategory(mydb,"Pb")
if verbose:
    dbfmt = gl.DbStringFormat()
    dbfmt.setParams(gl.FLAG_STATS)
    dbfmt.setNames(["Category*"])
    dbfmt.setMode(2)
    mydb.display(dbfmt)
----


----

Data Base Characteristics
=========================

Data Base Statistics
--------------------
14 - Name Category.Pb - Locator z1
 Nb of data          =        102
 Nb of active values =         99
 Class         1 =         12 (    12.121%)
 Class         2 =         51 (    51.515%)
 Class         3 =         36 (    36.364%)
 ----
